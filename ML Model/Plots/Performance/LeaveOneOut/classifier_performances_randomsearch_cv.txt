

Performance scores when doing LeaveOneGroupOut with SVM

 Performance: Auc = 0.592 (+-0.042, max: 0.656), Recall = 0.345 (+-0.083, max: 0.473), Specificity= 0.840 (+-0.071, max: 0.911), Precision = 0.341 (+-0.083, max: 0.468)
	 Confusion matrix: 
		[[4332  705]
		 [ 694  390]]
	Correctly classified data: 77.14% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.644, Recall = 0.444, Specificity= 0.845, Precision = 0.444
FM:		 Auc= 0.540, Recall = 0.217, Specificity= 0.864, Precision = 0.212
TW:		 Auc= 0.557, Recall = 0.473, Specificity= 0.640, Precision = 0.468
ZZ:		 Auc= 0.631, Recall = 0.379, Specificity= 0.883, Precision = 0.363
IS:		 Auc= 0.529, Recall = 0.268, Specificity= 0.789, Precision = 0.268
LZ:		 Auc= 0.569, Recall = 0.359, Specificity= 0.779, Precision = 0.359
MH:		 Auc= 0.629, Recall = 0.393, Specificity= 0.866, Precision = 0.382
MK:		 Auc= 0.572, Recall = 0.287, Specificity= 0.856, Precision = 0.284
MR:		 Auc= 0.611, Recall = 0.310, Specificity= 0.911, Precision = 0.310
NK:		 Auc= 0.617, Recall = 0.337, Specificity= 0.896, Precision = 0.337
PG:		 Auc= 0.656, Recall = 0.449, Specificity= 0.863, Precision = 0.449
ST:		 Auc= 0.554, Recall = 0.220, Specificity= 0.889, Precision = 0.220

Performance scores when doing LeaveOneGroupOut with Linear SVM

 Performance: Auc = 0.592 (+-0.042, max: 0.656), Recall = 0.345 (+-0.083, max: 0.473), Specificity= 0.840 (+-0.071, max: 0.911), Precision = 0.341 (+-0.083, max: 0.468)
	 Confusion matrix: 
		[[4332  705]
		 [ 694  390]]
	Correctly classified data: 77.14% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.644, Recall = 0.444, Specificity= 0.845, Precision = 0.444
FM:		 Auc= 0.540, Recall = 0.217, Specificity= 0.864, Precision = 0.212
TW:		 Auc= 0.557, Recall = 0.473, Specificity= 0.640, Precision = 0.468
ZZ:		 Auc= 0.631, Recall = 0.379, Specificity= 0.883, Precision = 0.363
IS:		 Auc= 0.529, Recall = 0.268, Specificity= 0.789, Precision = 0.268
LZ:		 Auc= 0.569, Recall = 0.359, Specificity= 0.779, Precision = 0.359
MH:		 Auc= 0.629, Recall = 0.393, Specificity= 0.866, Precision = 0.382
MK:		 Auc= 0.572, Recall = 0.287, Specificity= 0.856, Precision = 0.284
MR:		 Auc= 0.611, Recall = 0.310, Specificity= 0.911, Precision = 0.310
NK:		 Auc= 0.617, Recall = 0.337, Specificity= 0.896, Precision = 0.337
PG:		 Auc= 0.656, Recall = 0.449, Specificity= 0.863, Precision = 0.449
ST:		 Auc= 0.554, Recall = 0.220, Specificity= 0.889, Precision = 0.220

Performance scores when doing LeaveOneGroupOut with Nearest Neighbor

 Performance: Auc = 0.520 (+-0.016, max: 0.556), Recall = 0.088 (+-0.039, max: 0.157), Specificity= 0.951 (+-0.020, max: 0.993), Precision = 0.307 (+-0.171, max: 0.800)
	 Confusion matrix: 
		[[4786  251]
		 [ 984  100]]
	Correctly classified data: 79.82% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.540, Recall = 0.143, Specificity= 0.937, Precision = 0.388
FM:		 Auc= 0.521, Recall = 0.096, Specificity= 0.945, Precision = 0.229
TW:		 Auc= 0.518, Recall = 0.043, Specificity= 0.993, Precision = 0.800
ZZ:		 Auc= 0.515, Recall = 0.092, Specificity= 0.938, Precision = 0.205
IS:		 Auc= 0.504, Recall = 0.056, Specificity= 0.951, Precision = 0.250
LZ:		 Auc= 0.518, Recall = 0.128, Specificity= 0.907, Precision = 0.323
MH:		 Auc= 0.510, Recall = 0.056, Specificity= 0.965, Precision = 0.250
MK:		 Auc= 0.518, Recall = 0.099, Specificity= 0.937, Precision = 0.238
MR:		 Auc= 0.522, Recall = 0.085, Specificity= 0.960, Precision = 0.214
NK:		 Auc= 0.556, Recall = 0.157, Specificity= 0.955, Precision = 0.351
PG:		 Auc= 0.525, Recall = 0.087, Specificity= 0.963, Precision = 0.367
ST:		 Auc= 0.490, Recall = 0.020, Specificity= 0.960, Precision = 0.067

Performance scores when doing LeaveOneGroupOut with QDA

 Performance: Auc = 0.569 (+-0.037, max: 0.630), Recall = 0.255 (+-0.090, max: 0.398), Specificity= 0.884 (+-0.047, max: 0.957), Precision = 0.330 (+-0.071, max: 0.446)
	 Confusion matrix: 
		[[4475  562]
		 [ 795  289]]
	Correctly classified data: 77.83% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.630, Recall = 0.398, Specificity= 0.862, Precision = 0.445
FM:		 Auc= 0.540, Recall = 0.205, Specificity= 0.874, Precision = 0.215
TW:		 Auc= 0.500, Recall = 0.043, Specificity= 0.957, Precision = 0.400
ZZ:		 Auc= 0.607, Recall = 0.333, Specificity= 0.881, Precision = 0.330
IS:		 Auc= 0.538, Recall = 0.282, Specificity= 0.794, Precision = 0.282
LZ:		 Auc= 0.546, Recall = 0.295, Specificity= 0.796, Precision = 0.333
MH:		 Auc= 0.581, Recall = 0.271, Specificity= 0.892, Precision = 0.345
MK:		 Auc= 0.572, Recall = 0.248, Specificity= 0.897, Precision = 0.325
MR:		 Auc= 0.563, Recall = 0.183, Specificity= 0.942, Precision = 0.289
NK:		 Auc= 0.589, Recall = 0.265, Specificity= 0.913, Precision = 0.324
PG:		 Auc= 0.622, Recall = 0.354, Specificity= 0.890, Precision = 0.446
ST:		 Auc= 0.546, Recall = 0.180, Specificity= 0.912, Precision = 0.225

Performance scores when doing LeaveOneGroupOut with Naive Bayes

 Performance: Auc = 0.576 (+-0.043, max: 0.661), Recall = 0.266 (+-0.115, max: 0.449), Specificity= 0.886 (+-0.059, max: 1.000), Precision = 0.306 (+-0.118, max: 0.467)
	 Confusion matrix: 
		[[4468  569]
		 [ 777  307]]
	Correctly classified data: 78.01% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.637, Recall = 0.421, Specificity= 0.853, Precision = 0.444
FM:		 Auc= 0.545, Recall = 0.217, Specificity= 0.872, Precision = 0.222
TW:		 Auc= 0.500, Recall = 0.000, Specificity= 1.000, Precision = 0.000
ZZ:		 Auc= 0.584, Recall = 0.264, Specificity= 0.903, Precision = 0.324
IS:		 Auc= 0.531, Recall = 0.268, Specificity= 0.794, Precision = 0.271
LZ:		 Auc= 0.571, Recall = 0.359, Specificity= 0.783, Precision = 0.364
MH:		 Auc= 0.599, Recall = 0.308, Specificity= 0.890, Precision = 0.371
MK:		 Auc= 0.571, Recall = 0.287, Specificity= 0.854, Precision = 0.282
MR:		 Auc= 0.559, Recall = 0.183, Specificity= 0.935, Precision = 0.265
NK:		 Auc= 0.605, Recall = 0.277, Specificity= 0.934, Precision = 0.397
PG:		 Auc= 0.661, Recall = 0.449, Specificity= 0.873, Precision = 0.467
ST:		 Auc= 0.549, Recall = 0.160, Specificity= 0.937, Precision = 0.267