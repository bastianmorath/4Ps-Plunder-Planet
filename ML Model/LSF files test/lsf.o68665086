Sender: LSF System <lsfadmin@eu-ms-024-28>
Subject: Job 68665086: <python main.py -m 100> in cluster <euler> Done

Job <python main.py -m 100> was submitted from host <eu-ms-002-06> by user <morathba> in cluster <euler> at Sat Jul 14 17:21:51 2018.
Job was executed on host(s) <eu-ms-024-28>, in queue <normal.4h>, as user <morathba> in cluster <euler> at Sat Jul 14 17:22:16 2018.
</cluster/home/morathba> was used as the home directory.
</cluster/home/morathba/PP local/Code local/plunder planet/ML Model> was used as the working directory.
Started at Sat Jul 14 17:22:16 2018.
Terminated at Sat Jul 14 17:22:59 2018.
Results reported at Sat Jul 14 17:22:59 2018.

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py -m 100
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   64.34 sec.
    Max Memory :                                 508 MB
    Average Memory :                             397.00 MB
    Total Requested Memory :                     1024.00 MB
    Delta Memory :                               516.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                8
    Run time :                                   43 sec.
    Turnaround time :                            68 sec.

The output (if any) follows:

Using TensorFlow backend.
/cluster/home/morathba/.local/lib64/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.
2018-07-14 17:22:26.450460: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Loading dataframes...
Feature matrix already cached!
Feature matrix and labels created!

################# Get trained LSTM #################

Maxlen (=Max. #obstacles of logfiles) is 334, minlen is 237
Compiling lstm network...

Shape X: (16, 334, 10)
Shape y: (16, 334, 1)

Epoch 1/100

16/16 [==============================] - 1s 52ms/step - loss: 1.0877
Epoch 2/100

16/16 [==============================] - 0s 19ms/step - loss: 1.0781
Epoch 3/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0715
Epoch 4/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0604
Epoch 5/100

16/16 [==============================] - 0s 20ms/step - loss: 1.1499
Epoch 6/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0475
Epoch 7/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0653
Epoch 8/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0574
Epoch 9/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0558
Epoch 10/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0484
Epoch 11/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0418
Epoch 12/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0363
Epoch 13/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0329
Epoch 14/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0293
Epoch 15/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0422
Epoch 16/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0278
Epoch 17/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0305
Epoch 18/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0229
Epoch 19/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0206
Epoch 20/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0183
Epoch 21/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0195
Epoch 22/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0145
Epoch 23/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0193
Epoch 24/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0101
Epoch 25/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0168
Epoch 26/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0130
Epoch 27/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0125
Epoch 28/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0059
Epoch 29/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0029
Epoch 30/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0060
Epoch 31/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0045
Epoch 32/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0032
Epoch 33/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0079
Epoch 34/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9988
Epoch 35/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9997
Epoch 36/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0048
Epoch 37/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0089
Epoch 38/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9973
Epoch 39/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9997
Epoch 40/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0000
Epoch 41/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9958
Epoch 42/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9931
Epoch 43/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9950
Epoch 44/100

16/16 [==============================] - 0s 19ms/step - loss: 0.9930
Epoch 45/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9937
Epoch 46/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9964
Epoch 47/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9879
Epoch 48/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9890
Epoch 49/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9944
Epoch 50/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9873
Epoch 51/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9829
Epoch 52/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9915
Epoch 53/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9890
Epoch 54/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9848
Epoch 55/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9914
Epoch 56/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9838
Epoch 57/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9868
Epoch 58/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9865
Epoch 59/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9872
Epoch 60/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9854
Epoch 61/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9918
Epoch 62/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9862
Epoch 63/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9831
Epoch 64/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9837
Epoch 65/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9852
Epoch 66/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9817
Epoch 67/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9835
Epoch 68/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9846
Epoch 69/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9786
Epoch 70/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9763
Epoch 71/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9724
Epoch 72/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9684
Epoch 73/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9750
Epoch 74/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9773
Epoch 75/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9817
Epoch 76/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9917
Epoch 77/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0193
Epoch 78/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9995
Epoch 79/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0034
Epoch 80/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0041
Epoch 81/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0038
Epoch 82/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9987
Epoch 83/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0006
Epoch 84/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9932
Epoch 85/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9965
Epoch 86/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9929
Epoch 87/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9918
Epoch 88/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9883
Epoch 89/100

16/16 [==============================] - 0s 19ms/step - loss: 0.9879
Epoch 90/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9902
Epoch 91/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9887
Epoch 92/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9889
Epoch 93/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9775
Epoch 94/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9824
Epoch 95/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9864
Epoch 96/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9840
Epoch 97/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9854
Epoch 98/100

16/16 [==============================] - 0s 19ms/step - loss: 0.9774
Epoch 99/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9891
Epoch 100/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9870
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking_1 (Masking)          (None, 334, 10)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 334, 128)          71168     
_________________________________________________________________
activation_1 (Activation)    (None, 334, 128)          0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 334, 128)          0         
_________________________________________________________________
dense_1 (Dense)              (None, 334, 96)           12384     
_________________________________________________________________
activation_2 (Activation)    (None, 334, 96)           0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 334, 96)           0         
_________________________________________________________________
dense_2 (Dense)              (None, 334, 64)           6208      
_________________________________________________________________
activation_3 (Activation)    (None, 334, 64)           0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 334, 64)           0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 334, 2)            130       
=================================================================
Total params: 89,890
Trainable params: 89,890
Non-trainable params: 0
_________________________________________________________________
None
Performance training set: 
[0.7429343629343629, 0.5793974266762567, 0.582984737139627, 0.696057347670251, 0.5680241521068858, 0.6248615184099054, 0.6540459486959781, 0.7006802721088434, 0.574793875147232, 0.5846300846300846, 0.4998018057696543, 0.6629343629343629, 0.6138714733542319, 0.4811292270531401, 0.6491386217948718, 0.6422866750735603]


******** Scores for LSTM (Windows:  10, 5, 10) ******** 

	roc_auc: 0.616 (+-0.07), recall: 0.514 (+-0.21), specificity: 0.718, precision: 0.298 (+-0.08) 

	Confusion matrix: 	 [3232 1201] 
				 [391 520]



Performance test set: 
[0.5986705163499632, 0.5699528167000285, 0.6820393718203936]


******** Scores for LSTM (Windows:  10, 5, 10) ******** 

	roc_auc: 0.617 (+-0.05), recall: 0.503 (+-0.07), specificity: 0.731, precision: 0.235 (+-0.01) 

	Confusion matrix: 	 [602 222] 
				 [70 68]



Time elapsed: 37.90595269203186
