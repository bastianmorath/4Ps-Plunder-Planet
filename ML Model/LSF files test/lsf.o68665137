Sender: LSF System <lsfadmin@eu-ms-006-28>
Subject: Job 68665137: <python main.py -m 100> in cluster <euler> Done

Job <python main.py -m 100> was submitted from host <eu-ms-008-24> by user <morathba> in cluster <euler> at Sat Jul 14 17:23:22 2018.
Job was executed on host(s) <eu-ms-006-28>, in queue <normal.4h>, as user <morathba> in cluster <euler> at Sat Jul 14 17:23:47 2018.
</cluster/home/morathba> was used as the home directory.
</cluster/home/morathba/PP local/Code local/plunder planet/ML Model> was used as the working directory.
Started at Sat Jul 14 17:23:47 2018.
Terminated at Sat Jul 14 17:24:51 2018.
Results reported at Sat Jul 14 17:24:51 2018.

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py -m 100
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   109.44 sec.
    Max Memory :                                 569 MB
    Average Memory :                             421.33 MB
    Total Requested Memory :                     1024.00 MB
    Delta Memory :                               455.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                8
    Run time :                                   87 sec.
    Turnaround time :                            89 sec.

The output (if any) follows:

Using TensorFlow backend.
/cluster/home/morathba/.local/lib64/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.
2018-07-14 17:23:57.806295: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Loading dataframes...
Feature matrix already cached!
Feature matrix and labels created!

################# Get trained LSTM #################

Maxlen (=Max. #obstacles of logfiles) is 334, minlen is 281
Compiling lstm network...

Shape X: (16, 334, 10)
Shape y: (16, 334, 1)

Epoch 1/100

16/16 [==============================] - 2s 94ms/step - loss: 1.4114
Epoch 2/100

16/16 [==============================] - 1s 32ms/step - loss: 2.3756
Epoch 3/100

16/16 [==============================] - 1s 33ms/step - loss: 1.2476
Epoch 4/100

16/16 [==============================] - 1s 33ms/step - loss: 1.1534
Epoch 5/100

16/16 [==============================] - 1s 32ms/step - loss: 1.0421
Epoch 6/100

16/16 [==============================] - 1s 33ms/step - loss: 1.0102
Epoch 7/100

16/16 [==============================] - 1s 32ms/step - loss: 1.0164
Epoch 8/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9880
Epoch 9/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9881
Epoch 10/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9732
Epoch 11/100

16/16 [==============================] - 1s 33ms/step - loss: 0.9723
Epoch 12/100

16/16 [==============================] - 1s 33ms/step - loss: 0.9637
Epoch 13/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9625
Epoch 14/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9571
Epoch 15/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9576
Epoch 16/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9532
Epoch 17/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9539
Epoch 18/100

16/16 [==============================] - 1s 33ms/step - loss: 0.9510
Epoch 19/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9481
Epoch 20/100

16/16 [==============================] - 1s 33ms/step - loss: 0.9455
Epoch 21/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9440
Epoch 22/100

16/16 [==============================] - 1s 33ms/step - loss: 0.9416
Epoch 23/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9400
Epoch 24/100

16/16 [==============================] - 1s 33ms/step - loss: 0.9369
Epoch 25/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9381
Epoch 26/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9356
Epoch 27/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9327
Epoch 28/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9337
Epoch 29/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9268
Epoch 30/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9264
Epoch 31/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9243
Epoch 32/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9215
Epoch 33/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9238
Epoch 34/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9186
Epoch 35/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9241
Epoch 36/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9183
Epoch 37/100

16/16 [==============================] - 1s 33ms/step - loss: 0.9157
Epoch 38/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9117
Epoch 39/100

16/16 [==============================] - 1s 33ms/step - loss: 0.9073
Epoch 40/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9050
Epoch 41/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9028
Epoch 42/100

16/16 [==============================] - 1s 32ms/step - loss: 0.8992
Epoch 43/100

16/16 [==============================] - 1s 33ms/step - loss: 0.8969
Epoch 44/100

16/16 [==============================] - 1s 33ms/step - loss: 0.8937
Epoch 45/100

16/16 [==============================] - 1s 32ms/step - loss: 0.8904
Epoch 46/100

16/16 [==============================] - 1s 33ms/step - loss: 0.8917
Epoch 47/100

16/16 [==============================] - 1s 33ms/step - loss: 0.9062
Epoch 48/100

16/16 [==============================] - 1s 32ms/step - loss: 0.8966
Epoch 49/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9103
Epoch 50/100

16/16 [==============================] - 1s 33ms/step - loss: 0.9103
Epoch 51/100

16/16 [==============================] - 1s 32ms/step - loss: 0.9044
Epoch 52/100

16/16 [==============================] - 1s 32ms/step - loss: 0.8974
Epoch 53/100

16/16 [==============================] - 1s 32ms/step - loss: 0.8925
Epoch 54/100

16/16 [==============================] - 1s 32ms/step - loss: 0.8920
Epoch 55/100

16/16 [==============================] - 1s 33ms/step - loss: 0.8868
Epoch 56/100

16/16 [==============================] - 1s 33ms/step - loss: 0.8817
Epoch 57/100

16/16 [==============================] - 1s 32ms/step - loss: 0.8766
Epoch 58/100

16/16 [==============================] - 1s 33ms/step - loss: 0.8727
Epoch 59/100

16/16 [==============================] - 1s 33ms/step - loss: 0.8669
Epoch 60/100

16/16 [==============================] - 1s 33ms/step - loss: 0.8664
Epoch 61/100

16/16 [==============================] - 1s 33ms/step - loss: 0.8590
Epoch 62/100

16/16 [==============================] - 1s 32ms/step - loss: 0.8538
Epoch 63/100

16/16 [==============================] - 1s 33ms/step - loss: 0.8510
Epoch 64/100

16/16 [==============================] - 1s 33ms/step - loss: 0.8465
Epoch 65/100

16/16 [==============================] - 1s 32ms/step - loss: 0.8389
Epoch 66/100

16/16 [==============================] - 1s 32ms/step - loss: 0.8353
Epoch 67/100

16/16 [==============================] - 1s 32ms/step - loss: 0.8339
Epoch 68/100

16/16 [==============================] - 1s 33ms/step - loss: 0.8341
Epoch 69/100

16/16 [==============================] - 1s 32ms/step - loss: 0.8225
Epoch 70/100

16/16 [==============================] - 1s 32ms/step - loss: 0.8206
Epoch 71/100

16/16 [==============================] - 1s 32ms/step - loss: 0.8132
Epoch 72/100

16/16 [==============================] - 1s 32ms/step - loss: 0.8170
Epoch 73/100

16/16 [==============================] - 1s 32ms/step - loss: 0.8064
Epoch 74/100

16/16 [==============================] - 1s 33ms/step - loss: 0.8071
Epoch 75/100

16/16 [==============================] - 1s 32ms/step - loss: 0.8096
Epoch 76/100

16/16 [==============================] - 1s 33ms/step - loss: 0.8059
Epoch 77/100

16/16 [==============================] - 1s 33ms/step - loss: 0.8297
Epoch 78/100

16/16 [==============================] - 1s 32ms/step - loss: 0.7993
Epoch 79/100

16/16 [==============================] - 1s 32ms/step - loss: 0.7961
Epoch 80/100

16/16 [==============================] - 1s 33ms/step - loss: 0.7924
Epoch 81/100

16/16 [==============================] - 1s 33ms/step - loss: 0.7804
Epoch 82/100

16/16 [==============================] - 1s 32ms/step - loss: 0.7751
Epoch 83/100

16/16 [==============================] - 1s 33ms/step - loss: 0.7722
Epoch 84/100

16/16 [==============================] - 1s 32ms/step - loss: 0.7775
Epoch 85/100

16/16 [==============================] - 1s 32ms/step - loss: 0.7819
Epoch 86/100

16/16 [==============================] - 1s 33ms/step - loss: 0.7639
Epoch 87/100

16/16 [==============================] - 1s 32ms/step - loss: 0.7526
Epoch 88/100

16/16 [==============================] - 1s 32ms/step - loss: 0.7474
Epoch 89/100

16/16 [==============================] - 1s 33ms/step - loss: 0.7412
Epoch 90/100

16/16 [==============================] - 1s 33ms/step - loss: 0.7314
Epoch 91/100

16/16 [==============================] - 1s 32ms/step - loss: 0.7333
Epoch 92/100

16/16 [==============================] - 1s 32ms/step - loss: 0.7282
Epoch 93/100

16/16 [==============================] - 1s 32ms/step - loss: 0.7226
Epoch 94/100

16/16 [==============================] - 1s 32ms/step - loss: 0.7184
Epoch 95/100

16/16 [==============================] - 1s 32ms/step - loss: 0.7352
Epoch 96/100

16/16 [==============================] - 1s 32ms/step - loss: 0.7226
Epoch 97/100

16/16 [==============================] - 1s 32ms/step - loss: 0.7177
Epoch 98/100

16/16 [==============================] - 1s 32ms/step - loss: 0.7017
Epoch 99/100

16/16 [==============================] - 1s 33ms/step - loss: 0.7122
Epoch 100/100

16/16 [==============================] - 1s 32ms/step - loss: 0.7277
/cluster/home/morathba/.local/lib64/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking_1 (Masking)          (None, 334, 10)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 334, 196)          162288    
_________________________________________________________________
activation_1 (Activation)    (None, 334, 196)          0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 334, 196)          784       
_________________________________________________________________
dense_1 (Dense)              (None, 334, 128)          25216     
_________________________________________________________________
activation_2 (Activation)    (None, 334, 128)          0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 334, 128)          512       
_________________________________________________________________
dense_2 (Dense)              (None, 334, 32)           4128      
_________________________________________________________________
activation_3 (Activation)    (None, 334, 32)           0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 334, 32)           128       
_________________________________________________________________
time_distributed_1 (TimeDist (None, 334, 2)            66        
=================================================================
Total params: 193,122
Trainable params: 192,410
Non-trainable params: 712
_________________________________________________________________
None
Performance training set: 
[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]


******** Scores for LSTM (Windows:  10, 5, 10) ******** 

	roc_auc: 0.500 (+-0.00), recall: 0.000 (+-0.00), specificity: 1.000, precision: 0.000 (+-0.00) 

	Confusion matrix: 	 [4487    0] 
				 [857   0]



Performance test set: 
[0.5, 0.5, 0.5]


******** Scores for LSTM (Windows:  10, 5, 10) ******** 

	roc_auc: 0.500 (+-0.00), recall: 0.000 (+-0.00), specificity: 1.000, precision: 0.000 (+-0.00) 

	Confusion matrix: 	 [711   0] 
				 [192   0]



Time elapsed: 59.42013335227966
