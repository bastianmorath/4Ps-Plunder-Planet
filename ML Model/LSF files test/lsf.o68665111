Sender: LSF System <lsfadmin@eu-ms-019-32>
Subject: Job 68665111: <python main.py -m 100> in cluster <euler> Done

Job <python main.py -m 100> was submitted from host <eu-ms-005-31> by user <morathba> in cluster <euler> at Sat Jul 14 17:22:22 2018.
Job was executed on host(s) <eu-ms-019-32>, in queue <normal.4h>, as user <morathba> in cluster <euler> at Sat Jul 14 17:22:44 2018.
</cluster/home/morathba> was used as the home directory.
</cluster/home/morathba/PP local/Code local/plunder planet/ML Model> was used as the working directory.
Started at Sat Jul 14 17:22:44 2018.
Terminated at Sat Jul 14 17:23:32 2018.
Results reported at Sat Jul 14 17:23:32 2018.

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py -m 100
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   71.95 sec.
    Max Memory :                                 520 MB
    Average Memory :                             404.50 MB
    Total Requested Memory :                     1024.00 MB
    Delta Memory :                               504.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                8
    Run time :                                   49 sec.
    Turnaround time :                            70 sec.

The output (if any) follows:

Using TensorFlow backend.
/cluster/home/morathba/.local/lib64/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.
2018-07-14 17:22:54.970797: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Loading dataframes...
Feature matrix already cached!
Feature matrix and labels created!

################# Get trained LSTM #################

Maxlen (=Max. #obstacles of logfiles) is 334, minlen is 237
Compiling lstm network...

Shape X: (16, 334, 10)
Shape y: (16, 334, 1)

Epoch 1/100

16/16 [==============================] - 1s 84ms/step - loss: 1.2418
Epoch 2/100

16/16 [==============================] - 0s 21ms/step - loss: 1.5814
Epoch 3/100

16/16 [==============================] - 0s 22ms/step - loss: 1.4620
Epoch 4/100

16/16 [==============================] - 0s 21ms/step - loss: 1.2020
Epoch 5/100

16/16 [==============================] - 0s 22ms/step - loss: 1.0316
Epoch 6/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0088
Epoch 7/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9915
Epoch 8/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9739
Epoch 9/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9667
Epoch 10/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9648
Epoch 11/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9598
Epoch 12/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9575
Epoch 13/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9515
Epoch 14/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9473
Epoch 15/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9444
Epoch 16/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9380
Epoch 17/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9367
Epoch 18/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9311
Epoch 19/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9280
Epoch 20/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9234
Epoch 21/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9177
Epoch 22/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9140
Epoch 23/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9097
Epoch 24/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9047
Epoch 25/100

16/16 [==============================] - 0s 22ms/step - loss: 0.8995
Epoch 26/100

16/16 [==============================] - 0s 22ms/step - loss: 0.8947
Epoch 27/100

16/16 [==============================] - 0s 21ms/step - loss: 0.8899
Epoch 28/100

16/16 [==============================] - 0s 21ms/step - loss: 0.8862
Epoch 29/100

16/16 [==============================] - 0s 22ms/step - loss: 0.8824
Epoch 30/100

16/16 [==============================] - 0s 21ms/step - loss: 0.8817
Epoch 31/100

16/16 [==============================] - 0s 21ms/step - loss: 0.8717
Epoch 32/100

16/16 [==============================] - 0s 22ms/step - loss: 0.8669
Epoch 33/100

16/16 [==============================] - 0s 22ms/step - loss: 0.8591
Epoch 34/100

16/16 [==============================] - 0s 22ms/step - loss: 0.8521
Epoch 35/100

16/16 [==============================] - 0s 21ms/step - loss: 0.8470
Epoch 36/100

16/16 [==============================] - 0s 22ms/step - loss: 0.8382
Epoch 37/100

16/16 [==============================] - 0s 22ms/step - loss: 0.8322
Epoch 38/100

16/16 [==============================] - 0s 22ms/step - loss: 0.8366
Epoch 39/100

16/16 [==============================] - 0s 22ms/step - loss: 0.8283
Epoch 40/100

16/16 [==============================] - 0s 22ms/step - loss: 0.8246
Epoch 41/100

16/16 [==============================] - 0s 22ms/step - loss: 0.8069
Epoch 42/100

16/16 [==============================] - 0s 22ms/step - loss: 0.8156
Epoch 43/100

16/16 [==============================] - 0s 22ms/step - loss: 0.8393
Epoch 44/100

16/16 [==============================] - 0s 22ms/step - loss: 0.8715
Epoch 45/100

16/16 [==============================] - 0s 22ms/step - loss: 0.8219
Epoch 46/100

16/16 [==============================] - 0s 22ms/step - loss: 0.8370
Epoch 47/100

16/16 [==============================] - 0s 22ms/step - loss: 0.7940
Epoch 48/100

16/16 [==============================] - 0s 23ms/step - loss: 0.8028
Epoch 49/100

16/16 [==============================] - 0s 23ms/step - loss: 0.7868
Epoch 50/100

16/16 [==============================] - 0s 22ms/step - loss: 0.7787
Epoch 51/100

16/16 [==============================] - 0s 22ms/step - loss: 0.7666
Epoch 52/100

16/16 [==============================] - 0s 22ms/step - loss: 0.7546
Epoch 53/100

16/16 [==============================] - 0s 22ms/step - loss: 0.7496
Epoch 54/100

16/16 [==============================] - 0s 22ms/step - loss: 0.7430
Epoch 55/100

16/16 [==============================] - 0s 22ms/step - loss: 0.7280
Epoch 56/100

16/16 [==============================] - 0s 22ms/step - loss: 0.7114
Epoch 57/100

16/16 [==============================] - 0s 22ms/step - loss: 0.7041
Epoch 58/100

16/16 [==============================] - 0s 22ms/step - loss: 0.6908
Epoch 59/100

16/16 [==============================] - 0s 22ms/step - loss: 0.6772
Epoch 60/100

16/16 [==============================] - 0s 22ms/step - loss: 0.6747
Epoch 61/100

16/16 [==============================] - 0s 22ms/step - loss: 0.6699
Epoch 62/100

16/16 [==============================] - 0s 22ms/step - loss: 0.6582
Epoch 63/100

16/16 [==============================] - 0s 22ms/step - loss: 0.6512
Epoch 64/100

16/16 [==============================] - 0s 22ms/step - loss: 0.6943
Epoch 65/100

16/16 [==============================] - 0s 22ms/step - loss: 0.6476
Epoch 66/100

16/16 [==============================] - 0s 22ms/step - loss: 0.6278
Epoch 67/100

16/16 [==============================] - 0s 22ms/step - loss: 0.6274
Epoch 68/100

16/16 [==============================] - 0s 22ms/step - loss: 0.6148
Epoch 69/100

16/16 [==============================] - 0s 22ms/step - loss: 0.5975
Epoch 70/100

16/16 [==============================] - 0s 22ms/step - loss: 0.5835
Epoch 71/100

16/16 [==============================] - 0s 22ms/step - loss: 0.5755
Epoch 72/100

16/16 [==============================] - 0s 22ms/step - loss: 0.5492
Epoch 73/100

16/16 [==============================] - 0s 23ms/step - loss: 0.5494
Epoch 74/100

16/16 [==============================] - 0s 22ms/step - loss: 0.5514
Epoch 75/100

16/16 [==============================] - 0s 22ms/step - loss: 0.5502
Epoch 76/100

16/16 [==============================] - 0s 22ms/step - loss: 0.5270
Epoch 77/100

16/16 [==============================] - 0s 22ms/step - loss: 0.5149
Epoch 78/100

16/16 [==============================] - 0s 22ms/step - loss: 0.5047
Epoch 79/100

16/16 [==============================] - 0s 22ms/step - loss: 0.5206
Epoch 80/100

16/16 [==============================] - 0s 22ms/step - loss: 0.5132
Epoch 81/100

16/16 [==============================] - 0s 22ms/step - loss: 0.5215
Epoch 82/100

16/16 [==============================] - 0s 22ms/step - loss: 0.5141
Epoch 83/100

16/16 [==============================] - 0s 22ms/step - loss: 0.4748
Epoch 84/100

16/16 [==============================] - 0s 23ms/step - loss: 0.4823
Epoch 85/100

16/16 [==============================] - 0s 22ms/step - loss: 0.4734
Epoch 86/100

16/16 [==============================] - 0s 22ms/step - loss: 0.4788
Epoch 87/100

16/16 [==============================] - 0s 23ms/step - loss: 0.4453
Epoch 88/100

16/16 [==============================] - 0s 22ms/step - loss: 0.4590
Epoch 89/100

16/16 [==============================] - 0s 22ms/step - loss: 0.4307
Epoch 90/100

16/16 [==============================] - 0s 22ms/step - loss: 0.4043
Epoch 91/100

16/16 [==============================] - 0s 22ms/step - loss: 0.3989
Epoch 92/100

16/16 [==============================] - 0s 22ms/step - loss: 0.3832
Epoch 93/100

16/16 [==============================] - 0s 22ms/step - loss: 0.3613
Epoch 94/100

16/16 [==============================] - 0s 22ms/step - loss: 0.3591
Epoch 95/100

16/16 [==============================] - 0s 22ms/step - loss: 0.3510
Epoch 96/100

16/16 [==============================] - 0s 22ms/step - loss: 0.3700
Epoch 97/100

16/16 [==============================] - 0s 22ms/step - loss: 0.3827
Epoch 98/100

16/16 [==============================] - 0s 22ms/step - loss: 0.4248
Epoch 99/100

16/16 [==============================] - 0s 22ms/step - loss: 0.3745
Epoch 100/100

16/16 [==============================] - 0s 22ms/step - loss: 0.3621
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking_1 (Masking)          (None, 334, 10)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 334, 128)          71168     
_________________________________________________________________
activation_1 (Activation)    (None, 334, 128)          0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 334, 128)          512       
_________________________________________________________________
dense_1 (Dense)              (None, 334, 96)           12384     
_________________________________________________________________
activation_2 (Activation)    (None, 334, 96)           0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 334, 96)           384       
_________________________________________________________________
dense_2 (Dense)              (None, 334, 64)           6208      
_________________________________________________________________
activation_3 (Activation)    (None, 334, 64)           0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 334, 64)           256       
_________________________________________________________________
time_distributed_1 (TimeDist (None, 334, 2)            130       
=================================================================
Total params: 91,042
Trainable params: 90,466
Non-trainable params: 576
_________________________________________________________________
None
Performance training set: 
[0.518043758043758, 0.5575420673076923, 0.4275659824046921, 0.5362916902204636, 0.5298047276464541, 0.5251221896383186, 0.6171327901343316, 0.48883414555775717, 0.4303835699184536, 0.5794337194337195, 0.5311675857108606, 0.493131038647343, 0.5004702194357367, 0.4950900163666121, 0.43273809523809526, 0.5128871336520474]


******** Scores for LSTM (Windows:  10, 5, 10) ******** 

	roc_auc: 0.511 (+-0.05), recall: 0.247 (+-0.10), specificity: 0.775, precision: 0.201 (+-0.12) 

	Confusion matrix: 	 [3442 1004] 
				 [664 234]



Performance test set: 
[0.49845565030551264, 0.4695550351288057, 0.5298638332989479]


******** Scores for LSTM (Windows:  10, 5, 10) ******** 

	roc_auc: 0.499 (+-0.02), recall: 0.206 (+-0.10), specificity: 0.792, precision: 0.148 (+-0.02) 

	Confusion matrix: 	 [627 168] 
				 [121  30]



Time elapsed: 42.589415550231934
