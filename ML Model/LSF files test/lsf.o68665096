Sender: LSF System <lsfadmin@eu-ms-007-25>
Subject: Job 68665096: <python main.py -m 100> in cluster <euler> Done

Job <python main.py -m 100> was submitted from host <eu-ms-004-17> by user <morathba> in cluster <euler> at Sat Jul 14 17:21:52 2018.
Job was executed on host(s) <eu-ms-007-25>, in queue <normal.4h>, as user <morathba> in cluster <euler> at Sat Jul 14 17:22:16 2018.
</cluster/home/morathba> was used as the home directory.
</cluster/home/morathba/PP local/Code local/plunder planet/ML Model> was used as the working directory.
Started at Sat Jul 14 17:22:16 2018.
Terminated at Sat Jul 14 17:23:01 2018.
Results reported at Sat Jul 14 17:23:01 2018.

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py -m 100
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   69.06 sec.
    Max Memory :                                 368 MB
    Average Memory :                             193.00 MB
    Total Requested Memory :                     1024.00 MB
    Delta Memory :                               656.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                8
    Run time :                                   46 sec.
    Turnaround time :                            69 sec.

The output (if any) follows:

Using TensorFlow backend.
/cluster/home/morathba/.local/lib64/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.
2018-07-14 17:22:26.613494: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Loading dataframes...
Feature matrix already cached!
Feature matrix and labels created!

################# Get trained LSTM #################

Maxlen (=Max. #obstacles of logfiles) is 334, minlen is 237
Compiling lstm network...

Shape X: (16, 334, 10)
Shape y: (16, 334, 1)

Epoch 1/100

16/16 [==============================] - 1s 56ms/step - loss: 1.0863
Epoch 2/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0735
Epoch 3/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0605
Epoch 4/100

16/16 [==============================] - 0s 21ms/step - loss: 1.2425
Epoch 5/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0537
Epoch 6/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0706
Epoch 7/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0628
Epoch 8/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0640
Epoch 9/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0653
Epoch 10/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0562
Epoch 11/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0505
Epoch 12/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0518
Epoch 13/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0462
Epoch 14/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0437
Epoch 15/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0416
Epoch 16/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0374
Epoch 17/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0303
Epoch 18/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0260
Epoch 19/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0291
Epoch 20/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0207
Epoch 21/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0269
Epoch 22/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0222
Epoch 23/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0267
Epoch 24/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0173
Epoch 25/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0181
Epoch 26/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0238
Epoch 27/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0171
Epoch 28/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0169
Epoch 29/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0131
Epoch 30/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0161
Epoch 31/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0055
Epoch 32/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0045
Epoch 33/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0125
Epoch 34/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0077
Epoch 35/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0084
Epoch 36/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0046
Epoch 37/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0136
Epoch 38/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0151
Epoch 39/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0031
Epoch 40/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0123
Epoch 41/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0100
Epoch 42/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9987
Epoch 43/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0018
Epoch 44/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9998
Epoch 45/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0080
Epoch 46/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0025
Epoch 47/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0003
Epoch 48/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0092
Epoch 49/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0009
Epoch 50/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9962
Epoch 51/100

16/16 [==============================] - 0s 20ms/step - loss: 0.9978
Epoch 52/100

16/16 [==============================] - 0s 20ms/step - loss: 1.0004
Epoch 53/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9954
Epoch 54/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9916
Epoch 55/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9990
Epoch 56/100

16/16 [==============================] - 0s 24ms/step - loss: 0.9934
Epoch 57/100

16/16 [==============================] - 0s 24ms/step - loss: 0.9943
Epoch 58/100

16/16 [==============================] - 0s 24ms/step - loss: 0.9979
Epoch 59/100

16/16 [==============================] - 0s 25ms/step - loss: 0.9866
Epoch 60/100

16/16 [==============================] - 0s 24ms/step - loss: 0.9896
Epoch 61/100

16/16 [==============================] - 0s 24ms/step - loss: 0.9852
Epoch 62/100

16/16 [==============================] - 0s 24ms/step - loss: 0.9851
Epoch 63/100

16/16 [==============================] - 0s 24ms/step - loss: 0.9913
Epoch 64/100

16/16 [==============================] - 0s 24ms/step - loss: 0.9947
Epoch 65/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0739
Epoch 66/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0164
Epoch 67/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0172
Epoch 68/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0122
Epoch 69/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0178
Epoch 70/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0093
Epoch 71/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0193
Epoch 72/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0035
Epoch 73/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0112
Epoch 74/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0057
Epoch 75/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0091
Epoch 76/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9998
Epoch 77/100

16/16 [==============================] - 0s 22ms/step - loss: 1.0041
Epoch 78/100

16/16 [==============================] - 0s 21ms/step - loss: 1.0005
Epoch 79/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9969
Epoch 80/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9979
Epoch 81/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9950
Epoch 82/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9900
Epoch 83/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9961
Epoch 84/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9929
Epoch 85/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9972
Epoch 86/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9937
Epoch 87/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9993
Epoch 88/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9904
Epoch 89/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9901
Epoch 90/100

16/16 [==============================] - 0s 21ms/step - loss: 0.9870
Epoch 91/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9827
Epoch 92/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9834
Epoch 93/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9775
Epoch 94/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9762
Epoch 95/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9743
Epoch 96/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9813
Epoch 97/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9747
Epoch 98/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9754
Epoch 99/100

16/16 [==============================] - 0s 22ms/step - loss: 0.9718
Epoch 100/100

16/16 [==============================] - 0s 23ms/step - loss: 0.9787
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking_1 (Masking)          (None, 334, 10)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 334, 128)          71168     
_________________________________________________________________
activation_1 (Activation)    (None, 334, 128)          0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 334, 128)          0         
_________________________________________________________________
dense_1 (Dense)              (None, 334, 96)           12384     
_________________________________________________________________
activation_2 (Activation)    (None, 334, 96)           0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 334, 96)           0         
_________________________________________________________________
dense_2 (Dense)              (None, 334, 64)           6208      
_________________________________________________________________
activation_3 (Activation)    (None, 334, 64)           0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 334, 64)           0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 334, 2)            130       
=================================================================
Total params: 89,890
Trainable params: 89,890
Non-trainable params: 0
_________________________________________________________________
None
Performance training set: 
[0.5011322463768116, 0.6222302287876058, 0.5103281215591279, 0.7324209840338873, 0.6242988782051282, 0.6790733590733592, 0.574242787500999, 0.6346270059759618, 0.7345173745173745, 0.5862634256642171, 0.6177714129841789, 0.6333476142023242, 0.5897260897260898, 0.558967112024666, 0.7256802721088436, 0.626653633105246]


******** Scores for LSTM (Windows:  10, 5, 10) ******** 

	roc_auc: 0.622 (+-0.07), recall: 0.555 (+-0.20), specificity: 0.689, precision: 0.298 (+-0.08) 

	Confusion matrix: 	 [3094 1329] 
				 [362 559]



Performance test set: 
[0.5523989898989898, 0.5740609496810772, 0.6236452112364521]


******** Scores for LSTM (Windows:  10, 5, 10) ******** 

	roc_auc: 0.583 (+-0.03), recall: 0.423 (+-0.11), specificity: 0.744, precision: 0.205 (+-0.04) 

	Confusion matrix: 	 [602 209] 
				 [76 52]



Time elapsed: 40.146544456481934
