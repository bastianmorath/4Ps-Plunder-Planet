Sender: LSF System <lsfadmin@eu-ms-015-18>
Subject: Job 68665139: <python main.py -m 300> in cluster <euler> Done

Job <python main.py -m 300> was submitted from host <eu-ms-008-24> by user <morathba> in cluster <euler> at Sat Jul 14 17:23:22 2018.
Job was executed on host(s) <eu-ms-015-18>, in queue <normal.4h>, as user <morathba> in cluster <euler> at Sat Jul 14 17:23:47 2018.
</cluster/home/morathba> was used as the home directory.
</cluster/home/morathba/PP local/Code local/plunder planet/ML Model> was used as the working directory.
Started at Sat Jul 14 17:23:47 2018.
Terminated at Sat Jul 14 17:26:34 2018.
Results reported at Sat Jul 14 17:26:34 2018.

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py -m 300
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   283.12 sec.
    Max Memory :                                 564 MB
    Average Memory :                             461.80 MB
    Total Requested Memory :                     1024.00 MB
    Delta Memory :                               460.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                8
    Run time :                                   169 sec.
    Turnaround time :                            192 sec.

The output (if any) follows:

Using TensorFlow backend.
/cluster/home/morathba/.local/lib64/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.
2018-07-14 17:23:57.726151: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Loading dataframes...
Feature matrix already cached!
Feature matrix and labels created!

################# Get trained LSTM #################

Maxlen (=Max. #obstacles of logfiles) is 334, minlen is 237
Compiling lstm network...

Shape X: (16, 334, 10)
Shape y: (16, 334, 1)

Epoch 1/300

16/16 [==============================] - 1s 92ms/step - loss: 1.7315
Epoch 2/300

16/16 [==============================] - 1s 32ms/step - loss: 1.6879
Epoch 3/300

16/16 [==============================] - 1s 32ms/step - loss: 1.0691
Epoch 4/300

16/16 [==============================] - 1s 32ms/step - loss: 1.0497
Epoch 5/300

16/16 [==============================] - 1s 32ms/step - loss: 1.0325
Epoch 6/300

16/16 [==============================] - 1s 32ms/step - loss: 1.0068
Epoch 7/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9957
Epoch 8/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9837
Epoch 9/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9710
Epoch 10/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9734
Epoch 11/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9641
Epoch 12/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9631
Epoch 13/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9582
Epoch 14/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9582
Epoch 15/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9524
Epoch 16/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9527
Epoch 17/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9495
Epoch 18/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9504
Epoch 19/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9482
Epoch 20/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9422
Epoch 21/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9516
Epoch 22/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9384
Epoch 23/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9314
Epoch 24/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9419
Epoch 25/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9351
Epoch 26/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9322
Epoch 27/300

16/16 [==============================] - 1s 33ms/step - loss: 0.9359
Epoch 28/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9313
Epoch 29/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9266
Epoch 30/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9254
Epoch 31/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9206
Epoch 32/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9177
Epoch 33/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9163
Epoch 34/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9107
Epoch 35/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9077
Epoch 36/300

16/16 [==============================] - 1s 32ms/step - loss: 0.9033
Epoch 37/300

16/16 [==============================] - 1s 32ms/step - loss: 0.8976
Epoch 38/300

16/16 [==============================] - 1s 32ms/step - loss: 0.8942
Epoch 39/300

16/16 [==============================] - 1s 32ms/step - loss: 0.8888
Epoch 40/300

16/16 [==============================] - 1s 32ms/step - loss: 0.8869
Epoch 41/300

16/16 [==============================] - 1s 32ms/step - loss: 0.8860
Epoch 42/300

16/16 [==============================] - 1s 32ms/step - loss: 0.8771
Epoch 43/300

16/16 [==============================] - 1s 32ms/step - loss: 0.8744
Epoch 44/300

16/16 [==============================] - 1s 32ms/step - loss: 0.8698
Epoch 45/300

16/16 [==============================] - 1s 32ms/step - loss: 0.8627
Epoch 46/300

16/16 [==============================] - 1s 32ms/step - loss: 0.8553
Epoch 47/300

16/16 [==============================] - 1s 32ms/step - loss: 0.8509
Epoch 48/300

16/16 [==============================] - 1s 32ms/step - loss: 0.8469
Epoch 49/300

16/16 [==============================] - 1s 32ms/step - loss: 0.8378
Epoch 50/300

16/16 [==============================] - 1s 32ms/step - loss: 0.8323
Epoch 51/300

16/16 [==============================] - 1s 32ms/step - loss: 0.8298
Epoch 52/300

16/16 [==============================] - 1s 32ms/step - loss: 0.8345
Epoch 53/300

16/16 [==============================] - 1s 32ms/step - loss: 0.8534
Epoch 54/300

16/16 [==============================] - 1s 32ms/step - loss: 0.8407
Epoch 55/300

16/16 [==============================] - 1s 32ms/step - loss: 0.8345
Epoch 56/300

16/16 [==============================] - 1s 33ms/step - loss: 0.8219
Epoch 57/300

16/16 [==============================] - 1s 33ms/step - loss: 0.8200
Epoch 58/300

16/16 [==============================] - 1s 33ms/step - loss: 0.8079
Epoch 59/300

16/16 [==============================] - 1s 33ms/step - loss: 0.8045
Epoch 60/300

16/16 [==============================] - 1s 33ms/step - loss: 0.7881
Epoch 61/300

16/16 [==============================] - 1s 33ms/step - loss: 0.7873
Epoch 62/300

16/16 [==============================] - 1s 32ms/step - loss: 0.7738
Epoch 63/300

16/16 [==============================] - 1s 32ms/step - loss: 0.7715
Epoch 64/300

16/16 [==============================] - 1s 33ms/step - loss: 0.7582
Epoch 65/300

16/16 [==============================] - 1s 33ms/step - loss: 0.7487
Epoch 66/300

16/16 [==============================] - 1s 32ms/step - loss: 0.7412
Epoch 67/300

16/16 [==============================] - 1s 33ms/step - loss: 0.7421
Epoch 68/300

16/16 [==============================] - 1s 32ms/step - loss: 0.7613
Epoch 69/300

16/16 [==============================] - 1s 32ms/step - loss: 0.7699
Epoch 70/300

16/16 [==============================] - 1s 32ms/step - loss: 0.7702
Epoch 71/300

16/16 [==============================] - 1s 33ms/step - loss: 0.7566
Epoch 72/300

16/16 [==============================] - 1s 32ms/step - loss: 0.7259
Epoch 73/300

16/16 [==============================] - 1s 33ms/step - loss: 0.7323
Epoch 74/300

16/16 [==============================] - 1s 32ms/step - loss: 0.7101
Epoch 75/300

16/16 [==============================] - 1s 33ms/step - loss: 0.7138
Epoch 76/300

16/16 [==============================] - 1s 33ms/step - loss: 0.6980
Epoch 77/300

16/16 [==============================] - 1s 33ms/step - loss: 0.6936
Epoch 78/300

16/16 [==============================] - 1s 32ms/step - loss: 0.7010
Epoch 79/300

16/16 [==============================] - 1s 33ms/step - loss: 0.7025
Epoch 80/300

16/16 [==============================] - 1s 33ms/step - loss: 0.6827
Epoch 81/300

16/16 [==============================] - 1s 33ms/step - loss: 0.6602
Epoch 82/300

16/16 [==============================] - 1s 33ms/step - loss: 0.6657
Epoch 83/300

16/16 [==============================] - 1s 33ms/step - loss: 0.6406
Epoch 84/300

16/16 [==============================] - 1s 33ms/step - loss: 0.6500
Epoch 85/300

16/16 [==============================] - 1s 33ms/step - loss: 0.6322
Epoch 86/300

16/16 [==============================] - 1s 33ms/step - loss: 0.6334
Epoch 87/300

16/16 [==============================] - 1s 33ms/step - loss: 0.6197
Epoch 88/300

16/16 [==============================] - 1s 33ms/step - loss: 0.6177
Epoch 89/300

16/16 [==============================] - 1s 33ms/step - loss: 0.6292
Epoch 90/300

16/16 [==============================] - 1s 33ms/step - loss: 0.6473
Epoch 91/300

16/16 [==============================] - 1s 32ms/step - loss: 0.5991
Epoch 92/300

16/16 [==============================] - 1s 32ms/step - loss: 0.5950
Epoch 93/300

16/16 [==============================] - 1s 32ms/step - loss: 0.5846
Epoch 94/300

16/16 [==============================] - 1s 32ms/step - loss: 0.5711
Epoch 95/300

16/16 [==============================] - 1s 33ms/step - loss: 0.5560
Epoch 96/300

16/16 [==============================] - 1s 33ms/step - loss: 0.5441
Epoch 97/300

16/16 [==============================] - 1s 32ms/step - loss: 0.5319
Epoch 98/300

16/16 [==============================] - 1s 33ms/step - loss: 0.5270
Epoch 99/300

16/16 [==============================] - 1s 33ms/step - loss: 0.5237
Epoch 100/300

16/16 [==============================] - 1s 33ms/step - loss: 0.5198
Epoch 101/300

16/16 [==============================] - 1s 33ms/step - loss: 0.5163
Epoch 102/300

16/16 [==============================] - 1s 33ms/step - loss: 0.5212
Epoch 103/300

16/16 [==============================] - 1s 32ms/step - loss: 0.4965
Epoch 104/300

16/16 [==============================] - 1s 33ms/step - loss: 0.5065
Epoch 105/300

16/16 [==============================] - 1s 32ms/step - loss: 0.5149
Epoch 106/300

16/16 [==============================] - 1s 32ms/step - loss: 0.4837
Epoch 107/300

16/16 [==============================] - 1s 32ms/step - loss: 0.4662
Epoch 108/300

16/16 [==============================] - 1s 33ms/step - loss: 0.4624
Epoch 109/300

16/16 [==============================] - 1s 32ms/step - loss: 0.4573
Epoch 110/300

16/16 [==============================] - 1s 32ms/step - loss: 0.4412
Epoch 111/300

16/16 [==============================] - 1s 33ms/step - loss: 0.4193
Epoch 112/300

16/16 [==============================] - 1s 33ms/step - loss: 0.4061
Epoch 113/300

16/16 [==============================] - 1s 33ms/step - loss: 0.4004
Epoch 114/300

16/16 [==============================] - 1s 33ms/step - loss: 0.3945
Epoch 115/300

16/16 [==============================] - 1s 32ms/step - loss: 0.3834
Epoch 116/300

16/16 [==============================] - 1s 32ms/step - loss: 0.3801
Epoch 117/300

16/16 [==============================] - 1s 32ms/step - loss: 0.3821
Epoch 118/300

16/16 [==============================] - 1s 32ms/step - loss: 0.3979
Epoch 119/300

16/16 [==============================] - 1s 33ms/step - loss: 0.4034
Epoch 120/300

16/16 [==============================] - 1s 32ms/step - loss: 0.3860
Epoch 121/300

16/16 [==============================] - 1s 33ms/step - loss: 0.3602
Epoch 122/300

16/16 [==============================] - 1s 32ms/step - loss: 0.3910
Epoch 123/300

16/16 [==============================] - 1s 32ms/step - loss: 0.3952
Epoch 124/300

16/16 [==============================] - 1s 33ms/step - loss: 0.3692
Epoch 125/300

16/16 [==============================] - 1s 32ms/step - loss: 0.3520
Epoch 126/300

16/16 [==============================] - 1s 32ms/step - loss: 0.3506
Epoch 127/300

16/16 [==============================] - 1s 32ms/step - loss: 0.3399
Epoch 128/300

16/16 [==============================] - 1s 33ms/step - loss: 0.3280
Epoch 129/300

16/16 [==============================] - 1s 33ms/step - loss: 0.3172
Epoch 130/300

16/16 [==============================] - 1s 33ms/step - loss: 0.2962
Epoch 131/300

16/16 [==============================] - 1s 33ms/step - loss: 0.2899
Epoch 132/300

16/16 [==============================] - 1s 32ms/step - loss: 0.2761
Epoch 133/300

16/16 [==============================] - 1s 33ms/step - loss: 0.2698
Epoch 134/300

16/16 [==============================] - 1s 32ms/step - loss: 0.2700
Epoch 135/300

16/16 [==============================] - 1s 33ms/step - loss: 0.2841
Epoch 136/300

16/16 [==============================] - 1s 32ms/step - loss: 0.2842
Epoch 137/300

16/16 [==============================] - 1s 33ms/step - loss: 0.2845
Epoch 138/300

16/16 [==============================] - 1s 33ms/step - loss: 0.2746
Epoch 139/300

16/16 [==============================] - 1s 32ms/step - loss: 0.2899
Epoch 140/300

16/16 [==============================] - 1s 33ms/step - loss: 0.3129
Epoch 141/300

16/16 [==============================] - 1s 33ms/step - loss: 0.3036
Epoch 142/300

16/16 [==============================] - 1s 32ms/step - loss: 0.2808
Epoch 143/300

16/16 [==============================] - 1s 33ms/step - loss: 0.2579
Epoch 144/300

16/16 [==============================] - 1s 33ms/step - loss: 0.2543
Epoch 145/300

16/16 [==============================] - 1s 33ms/step - loss: 0.2212
Epoch 146/300

16/16 [==============================] - 1s 33ms/step - loss: 0.2238
Epoch 147/300

16/16 [==============================] - 1s 32ms/step - loss: 0.2153
Epoch 148/300

16/16 [==============================] - 1s 32ms/step - loss: 0.1951
Epoch 149/300

16/16 [==============================] - 1s 32ms/step - loss: 0.1911
Epoch 150/300

16/16 [==============================] - 1s 33ms/step - loss: 0.1835
Epoch 151/300

16/16 [==============================] - 1s 33ms/step - loss: 0.1772
Epoch 152/300

16/16 [==============================] - 1s 32ms/step - loss: 0.1632
Epoch 153/300

16/16 [==============================] - 1s 32ms/step - loss: 0.1669
Epoch 154/300

16/16 [==============================] - 1s 32ms/step - loss: 0.1605
Epoch 155/300

16/16 [==============================] - 1s 32ms/step - loss: 0.1604
Epoch 156/300

16/16 [==============================] - 1s 32ms/step - loss: 0.1445
Epoch 157/300

16/16 [==============================] - 1s 32ms/step - loss: 0.1287
Epoch 158/300

16/16 [==============================] - 1s 32ms/step - loss: 0.1309
Epoch 159/300

16/16 [==============================] - 1s 32ms/step - loss: 0.1259
Epoch 160/300

16/16 [==============================] - 1s 33ms/step - loss: 0.1164
Epoch 161/300

16/16 [==============================] - 1s 32ms/step - loss: 0.1097
Epoch 162/300

16/16 [==============================] - 1s 33ms/step - loss: 0.1069
Epoch 163/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0966
Epoch 164/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0927
Epoch 165/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0898
Epoch 166/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0838
Epoch 167/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0813
Epoch 168/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0764
Epoch 169/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0737
Epoch 170/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0683
Epoch 171/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0646
Epoch 172/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0618
Epoch 173/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0582
Epoch 174/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0560
Epoch 175/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0531
Epoch 176/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0503
Epoch 177/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0474
Epoch 178/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0448
Epoch 179/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0433
Epoch 180/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0407
Epoch 181/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0384
Epoch 182/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0369
Epoch 183/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0347
Epoch 184/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0335
Epoch 185/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0319
Epoch 186/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0303
Epoch 187/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0291
Epoch 188/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0275
Epoch 189/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0265
Epoch 190/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0253
Epoch 191/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0243
Epoch 192/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0232
Epoch 193/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0222
Epoch 194/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0212
Epoch 195/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0204
Epoch 196/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0196
Epoch 197/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0188
Epoch 198/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0180
Epoch 199/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0174
Epoch 200/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0167
Epoch 201/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0161
Epoch 202/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0155
Epoch 203/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0150
Epoch 204/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0145
Epoch 205/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0139
Epoch 206/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0135
Epoch 207/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0131
Epoch 208/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0126
Epoch 209/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0122
Epoch 210/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0119
Epoch 211/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0115
Epoch 212/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0112
Epoch 213/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0108
Epoch 214/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0106
Epoch 215/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0102
Epoch 216/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0099
Epoch 217/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0097
Epoch 218/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0094
Epoch 219/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0092
Epoch 220/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0089
Epoch 221/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0087
Epoch 222/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0085
Epoch 223/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0083
Epoch 224/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0081
Epoch 225/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0079
Epoch 226/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0077
Epoch 227/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0075
Epoch 228/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0074
Epoch 229/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0072
Epoch 230/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0070
Epoch 231/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0069
Epoch 232/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0067
Epoch 233/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0066
Epoch 234/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0064
Epoch 235/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0063
Epoch 236/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0062
Epoch 237/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0060
Epoch 238/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0059
Epoch 239/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0058
Epoch 240/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0057
Epoch 241/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0056
Epoch 242/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0054
Epoch 243/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0053
Epoch 244/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0052
Epoch 245/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0051
Epoch 246/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0050
Epoch 247/300

16/16 [==============================] - 1s 32ms/step - loss: 0.0050
Epoch 248/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0049
Epoch 249/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0048
Epoch 250/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0047
Epoch 251/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0046
Epoch 252/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0045
Epoch 253/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0044
Epoch 254/300

16/16 [==============================] - 1s 33ms/step - loss: 0.0044
Epoch 255/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0043
Epoch 256/300

16/16 [==============================] - 0s 30ms/step - loss: 0.0042
Epoch 257/300

16/16 [==============================] - 0s 30ms/step - loss: 0.0042
Epoch 258/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0041
Epoch 259/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0040
Epoch 260/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0040
Epoch 261/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0039
Epoch 262/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0038
Epoch 263/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0038
Epoch 264/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0037
Epoch 265/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0037
Epoch 266/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0036
Epoch 267/300

16/16 [==============================] - 0s 30ms/step - loss: 0.0036
Epoch 268/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0035
Epoch 269/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0035
Epoch 270/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0034
Epoch 271/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0034
Epoch 272/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0033
Epoch 273/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0033
Epoch 274/300

16/16 [==============================] - 1s 31ms/step - loss: 0.0032
Epoch 275/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0032
Epoch 276/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0031
Epoch 277/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0031
Epoch 278/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0031
Epoch 279/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0030
Epoch 280/300

16/16 [==============================] - 0s 30ms/step - loss: 0.0030
Epoch 281/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0029
Epoch 282/300

16/16 [==============================] - 0s 30ms/step - loss: 0.0029
Epoch 283/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0029
Epoch 284/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0028
Epoch 285/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0028
Epoch 286/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0028
Epoch 287/300

16/16 [==============================] - 0s 30ms/step - loss: 0.0027
Epoch 288/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0027
Epoch 289/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0027
Epoch 290/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0026
Epoch 291/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0026
Epoch 292/300

16/16 [==============================] - 0s 30ms/step - loss: 0.0026
Epoch 293/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0025
Epoch 294/300

16/16 [==============================] - 0s 30ms/step - loss: 0.0025
Epoch 295/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0025
Epoch 296/300

16/16 [==============================] - 0s 30ms/step - loss: 0.0025
Epoch 297/300

16/16 [==============================] - 0s 30ms/step - loss: 0.0024
Epoch 298/300

16/16 [==============================] - 0s 30ms/step - loss: 0.0024
Epoch 299/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0024
Epoch 300/300

16/16 [==============================] - 0s 31ms/step - loss: 0.0023
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking_1 (Masking)          (None, 334, 10)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 334, 196)          162288    
_________________________________________________________________
activation_1 (Activation)    (None, 334, 196)          0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 334, 196)          784       
_________________________________________________________________
dense_1 (Dense)              (None, 334, 128)          25216     
_________________________________________________________________
activation_2 (Activation)    (None, 334, 128)          0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 334, 128)          512       
_________________________________________________________________
dense_2 (Dense)              (None, 334, 32)           4128      
_________________________________________________________________
activation_3 (Activation)    (None, 334, 32)           0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 334, 32)           128       
_________________________________________________________________
time_distributed_1 (TimeDist (None, 334, 2)            66        
=================================================================
Total params: 193,122
Trainable params: 192,410
Non-trainable params: 712
_________________________________________________________________
None
Performance training set: 
[0.52641065830721, 0.46407004830917875, 0.6199536897211315, 0.5222159412097229, 0.5513522319973932, 0.5580268663290024, 0.5375850340136055, 0.5278445512820513, 0.5695015416238438, 0.5922240869495724, 0.5127139194900574, 0.5549364613880743, 0.5636521947997357, 0.5615701415701416, 0.5066138454307393, 0.5859929078014184]


******** Scores for LSTM (Windows:  10, 5, 10) ******** 

	roc_auc: 0.547 (+-0.04), recall: 0.169 (+-0.06), specificity: 0.925, precision: 0.333 (+-0.15) 

	Confusion matrix: 	 [4140  338] 
				 [723 143]



Performance test set: 
[0.49442954404786466, 0.5180599727396638, 0.5256557377049181]


******** Scores for LSTM (Windows:  10, 5, 10) ******** 

	roc_auc: 0.513 (+-0.01), recall: 0.064 (+-0.03), specificity: 0.962, precision: 0.295 (+-0.15) 

	Confusion matrix: 	 [725  29] 
				 [170  13]



Time elapsed: 161.6822578907013
