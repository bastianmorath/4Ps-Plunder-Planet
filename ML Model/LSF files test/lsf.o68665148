Sender: LSF System <lsfadmin@eu-ms-027-17>
Subject: Job 68665148: <python main.py -m 100> in cluster <euler> Done

Job <python main.py -m 100> was submitted from host <eu-ms-019-01> by user <morathba> in cluster <euler> at Sat Jul 14 17:23:50 2018.
Job was executed on host(s) <eu-ms-027-17>, in queue <normal.4h>, as user <morathba> in cluster <euler> at Sat Jul 14 17:24:16 2018.
</cluster/home/morathba> was used as the home directory.
</cluster/home/morathba/PP local/Code local/plunder planet/ML Model> was used as the working directory.
Started at Sat Jul 14 17:24:16 2018.
Terminated at Sat Jul 14 17:27:33 2018.
Results reported at Sat Jul 14 17:27:33 2018.

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py -m 100
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   348.65 sec.
    Max Memory :                                 484 MB
    Average Memory :                             318.43 MB
    Total Requested Memory :                     1024.00 MB
    Delta Memory :                               540.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                8
    Run time :                                   227 sec.
    Turnaround time :                            223 sec.

The output (if any) follows:

Using TensorFlow backend.
/cluster/home/morathba/.local/lib64/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.
2018-07-14 17:24:26.566753: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Loading dataframes...
Feature matrix already cached!
Feature matrix and labels created!

################# Get trained LSTM #################

Maxlen (=Max. #obstacles of logfiles) is 334, minlen is 237
Compiling lstm network...

Shape X: (16, 334, 10)
Shape y: (16, 334, 1)

Epoch 1/100

16/16 [==============================] - 2s 152ms/step - loss: 1.0710
Epoch 2/100

16/16 [==============================] - 2s 114ms/step - loss: 1.1051
Epoch 3/100

16/16 [==============================] - 2s 115ms/step - loss: 1.8857
Epoch 4/100

16/16 [==============================] - 2s 116ms/step - loss: 1.2245
Epoch 5/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0858
Epoch 6/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0893
Epoch 7/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0962
Epoch 8/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0681
Epoch 9/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0767
Epoch 10/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0735
Epoch 11/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0690
Epoch 12/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0685
Epoch 13/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0677
Epoch 14/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0696
Epoch 15/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0702
Epoch 16/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0685
Epoch 17/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0692
Epoch 18/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0690
Epoch 19/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0693
Epoch 20/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0684
Epoch 21/100

16/16 [==============================] - 2s 114ms/step - loss: 1.0679
Epoch 22/100

16/16 [==============================] - 2s 113ms/step - loss: 1.0682
Epoch 23/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0681
Epoch 24/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0681
Epoch 25/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0686
Epoch 26/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0684
Epoch 27/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0688
Epoch 28/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0681
Epoch 29/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0682
Epoch 30/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0684
Epoch 31/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0683
Epoch 32/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0685
Epoch 33/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0684
Epoch 34/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0679
Epoch 35/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0684
Epoch 36/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0677
Epoch 37/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0681
Epoch 38/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0682
Epoch 39/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0686
Epoch 40/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0680
Epoch 41/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0676
Epoch 42/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0678
Epoch 43/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0678
Epoch 44/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0677
Epoch 45/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0686
Epoch 46/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0675
Epoch 47/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0681
Epoch 48/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0673
Epoch 49/100

16/16 [==============================] - 2s 114ms/step - loss: 1.0676
Epoch 50/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0675
Epoch 51/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0681
Epoch 52/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0671
Epoch 53/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0674
Epoch 54/100

16/16 [==============================] - 2s 113ms/step - loss: 1.0674
Epoch 55/100

16/16 [==============================] - 2s 114ms/step - loss: 1.0661
Epoch 56/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0665
Epoch 57/100

16/16 [==============================] - 2s 114ms/step - loss: 1.0654
Epoch 58/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0644
Epoch 59/100

16/16 [==============================] - 2s 114ms/step - loss: 1.0653
Epoch 60/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0627
Epoch 61/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0598
Epoch 62/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0564
Epoch 63/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0677
Epoch 64/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0766
Epoch 65/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0773
Epoch 66/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0713
Epoch 67/100

16/16 [==============================] - 2s 117ms/step - loss: 1.0634
Epoch 68/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0611
Epoch 69/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0649
Epoch 70/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0652
Epoch 71/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0630
Epoch 72/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0605
Epoch 73/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0610
Epoch 74/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0586
Epoch 75/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0602
Epoch 76/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0547
Epoch 77/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0540
Epoch 78/100

16/16 [==============================] - 2s 114ms/step - loss: 1.0448
Epoch 79/100

16/16 [==============================] - 2s 113ms/step - loss: 1.0575
Epoch 80/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0492
Epoch 81/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0466
Epoch 82/100

16/16 [==============================] - 2s 113ms/step - loss: 1.0493
Epoch 83/100

16/16 [==============================] - 2s 113ms/step - loss: 1.0286
Epoch 84/100

16/16 [==============================] - 2s 112ms/step - loss: 1.0478
Epoch 85/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0354
Epoch 86/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0289
Epoch 87/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0337
Epoch 88/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0302
Epoch 89/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0256
Epoch 90/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0183
Epoch 91/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0262
Epoch 92/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0148
Epoch 93/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0140
Epoch 94/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0132
Epoch 95/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0128
Epoch 96/100

16/16 [==============================] - 2s 116ms/step - loss: 1.0183
Epoch 97/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0055
Epoch 98/100

16/16 [==============================] - 2s 115ms/step - loss: 1.0092
Epoch 99/100

16/16 [==============================] - 2s 117ms/step - loss: 1.0091
Epoch 100/100

16/16 [==============================] - 2s 107ms/step - loss: 1.0138
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
masking_1 (Masking)          (None, 334, 10)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 334, 512)          1071104   
_________________________________________________________________
activation_1 (Activation)    (None, 334, 512)          0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 334, 512)          0         
_________________________________________________________________
dense_1 (Dense)              (None, 334, 256)          131328    
_________________________________________________________________
activation_2 (Activation)    (None, 334, 256)          0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 334, 256)          0         
_________________________________________________________________
dense_2 (Dense)              (None, 334, 128)          32896     
_________________________________________________________________
activation_3 (Activation)    (None, 334, 128)          0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 334, 128)          0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 334, 2)            258       
=================================================================
Total params: 1,235,586
Trainable params: 1,235,586
Non-trainable params: 0
_________________________________________________________________
None
Performance training set: 
[0.6325513196480939, 0.616035657051282, 0.6703589517727373, 0.7166280566280566, 0.5596979141692641, 0.520757850241546, 0.6813479623824451, 0.5723572639909554, 0.642353770260747, 0.5734750709580678, 0.5396325796505653, 0.657901596611274, 0.5545624610268136, 0.735374149659864, 0.6238095238095237, 0.5459095459095459]


******** Scores for LSTM (Windows:  10, 5, 10) ******** 

	roc_auc: 0.615 (+-0.06), recall: 0.473 (+-0.12), specificity: 0.757, precision: 0.284 (+-0.10) 

	Confusion matrix: 	 [3391 1070] 
				 [442 441]



Performance test set: 
[0.6089773719196938, 0.6099513869030597, 0.6271142336716107]


******** Scores for LSTM (Windows:  10, 5, 10) ******** 

	roc_auc: 0.615 (+-0.01), recall: 0.474 (+-0.02), specificity: 0.757, precision: 0.288 (+-0.03) 

	Confusion matrix: 	 [607 195] 
				 [87 79]



Time elapsed: 192.16181755065918
