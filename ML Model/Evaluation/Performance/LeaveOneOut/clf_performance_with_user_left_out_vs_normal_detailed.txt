

Performance scores when doing LeaveOneGroupOut with SVM

 Performance: Auc = 0.592 (+-0.042, max: 0.656), Recall = 0.345 (+-0.083, max: 0.473), Specificity= 0.840 (+-0.071, max: 0.911), Precision = 0.341 (+-0.083, max: 0.468)
	 Confusion matrix: 
		[[4332  705]
		 [ 694  390]]
	Correctly classified data: 77.14% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.644, Recall = 0.444, Specificity= 0.845, Precision = 0.444
FM:		 Auc= 0.540, Recall = 0.217, Specificity= 0.864, Precision = 0.212
TW:		 Auc= 0.557, Recall = 0.473, Specificity= 0.640, Precision = 0.468
ZZ:		 Auc= 0.631, Recall = 0.379, Specificity= 0.883, Precision = 0.363
IS:		 Auc= 0.529, Recall = 0.268, Specificity= 0.789, Precision = 0.268
LZ:		 Auc= 0.569, Recall = 0.359, Specificity= 0.779, Precision = 0.359
MH:		 Auc= 0.629, Recall = 0.393, Specificity= 0.866, Precision = 0.382
MK:		 Auc= 0.572, Recall = 0.287, Specificity= 0.856, Precision = 0.284
MR:		 Auc= 0.611, Recall = 0.310, Specificity= 0.911, Precision = 0.310
NK:		 Auc= 0.617, Recall = 0.337, Specificity= 0.896, Precision = 0.337
PG:		 Auc= 0.656, Recall = 0.449, Specificity= 0.863, Precision = 0.449
ST:		 Auc= 0.554, Recall = 0.220, Specificity= 0.889, Precision = 0.220

Performance scores when doing LeaveOneGroupOut with Linear SVM

 Performance: Auc = 0.592 (+-0.042, max: 0.656), Recall = 0.345 (+-0.083, max: 0.473), Specificity= 0.840 (+-0.071, max: 0.911), Precision = 0.341 (+-0.083, max: 0.468)
	 Confusion matrix: 
		[[4332  705]
		 [ 694  390]]
	Correctly classified data: 77.14% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.644, Recall = 0.444, Specificity= 0.845, Precision = 0.444
FM:		 Auc= 0.540, Recall = 0.217, Specificity= 0.864, Precision = 0.212
TW:		 Auc= 0.557, Recall = 0.473, Specificity= 0.640, Precision = 0.468
ZZ:		 Auc= 0.631, Recall = 0.379, Specificity= 0.883, Precision = 0.363
IS:		 Auc= 0.529, Recall = 0.268, Specificity= 0.789, Precision = 0.268
LZ:		 Auc= 0.569, Recall = 0.359, Specificity= 0.779, Precision = 0.359
MH:		 Auc= 0.629, Recall = 0.393, Specificity= 0.866, Precision = 0.382
MK:		 Auc= 0.572, Recall = 0.287, Specificity= 0.856, Precision = 0.284
MR:		 Auc= 0.611, Recall = 0.310, Specificity= 0.911, Precision = 0.310
NK:		 Auc= 0.617, Recall = 0.337, Specificity= 0.896, Precision = 0.337
PG:		 Auc= 0.656, Recall = 0.449, Specificity= 0.863, Precision = 0.449
ST:		 Auc= 0.554, Recall = 0.220, Specificity= 0.889, Precision = 0.220

Performance scores when doing LeaveOneGroupOut with Nearest Neighbor

 Performance: Auc = 0.517 (+-0.017, max: 0.549), Recall = 0.091 (+-0.029, max: 0.145), Specificity= 0.942 (+-0.021, max: 0.977), Precision = 0.278 (+-0.109, max: 0.526)
	 Confusion matrix: 
		[[4753  284]
		 [ 983  101]]
	Correctly classified data: 79.3% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.522, Recall = 0.105, Specificity= 0.939, Precision = 0.326
FM:		 Auc= 0.505, Recall = 0.084, Specificity= 0.925, Precision = 0.159
TW:		 Auc= 0.521, Recall = 0.108, Specificity= 0.935, Precision = 0.526
ZZ:		 Auc= 0.527, Recall = 0.126, Specificity= 0.928, Precision = 0.234
IS:		 Auc= 0.484, Recall = 0.056, Specificity= 0.911, Precision = 0.154
LZ:		 Auc= 0.527, Recall = 0.115, Specificity= 0.938, Precision = 0.391
MH:		 Auc= 0.512, Recall = 0.065, Specificity= 0.959, Precision = 0.250
MK:		 Auc= 0.490, Recall = 0.069, Specificity= 0.911, Precision = 0.135
MR:		 Auc= 0.530, Recall = 0.085, Specificity= 0.976, Precision = 0.316
NK:		 Auc= 0.549, Recall = 0.145, Specificity= 0.953, Precision = 0.324
PG:		 Auc= 0.523, Recall = 0.094, Specificity= 0.951, Precision = 0.324
ST:		 Auc= 0.509, Recall = 0.040, Specificity= 0.977, Precision = 0.200

Performance scores when doing LeaveOneGroupOut with QDA

 Performance: Auc = 0.546 (+-0.040, max: 0.619), Recall = 0.236 (+-0.123, max: 0.495), Specificity= 0.856 (+-0.136, max: 0.966), Precision = 0.309 (+-0.102, max: 0.486)
	 Confusion matrix: 
		[[4493  544]
		 [ 810  274]]
	Correctly classified data: 77.88% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.593, Recall = 0.308, Specificity= 0.878, Precision = 0.414
FM:		 Auc= 0.519, Recall = 0.133, Specificity= 0.905, Precision = 0.190
TW:		 Auc= 0.470, Recall = 0.495, Specificity= 0.446, Precision = 0.374
ZZ:		 Auc= 0.541, Recall = 0.172, Specificity= 0.909, Precision = 0.250
IS:		 Auc= 0.539, Recall = 0.296, Specificity= 0.781, Precision = 0.280
LZ:		 Auc= 0.554, Recall = 0.321, Specificity= 0.788, Precision = 0.342
MH:		 Auc= 0.574, Recall = 0.234, Specificity= 0.914, Precision = 0.362
MK:		 Auc= 0.545, Recall = 0.188, Specificity= 0.901, Precision = 0.275
MR:		 Auc= 0.510, Recall = 0.056, Specificity= 0.964, Precision = 0.167
NK:		 Auc= 0.585, Recall = 0.205, Specificity= 0.966, Precision = 0.486
PG:		 Auc= 0.619, Recall = 0.370, Specificity= 0.869, Precision = 0.412
ST:		 Auc= 0.507, Recall = 0.060, Specificity= 0.954, Precision = 0.158

Performance scores when doing LeaveOneGroupOut with Naive Bayes

 Performance: Auc = 0.576 (+-0.043, max: 0.661), Recall = 0.266 (+-0.115, max: 0.449), Specificity= 0.886 (+-0.059, max: 1.000), Precision = 0.306 (+-0.118, max: 0.467)
	 Confusion matrix: 
		[[4468  569]
		 [ 777  307]]
	Correctly classified data: 78.01% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.637, Recall = 0.421, Specificity= 0.853, Precision = 0.444
FM:		 Auc= 0.545, Recall = 0.217, Specificity= 0.872, Precision = 0.222
TW:		 Auc= 0.500, Recall = 0.000, Specificity= 1.000, Precision = 0.000
ZZ:		 Auc= 0.584, Recall = 0.264, Specificity= 0.903, Precision = 0.324
IS:		 Auc= 0.531, Recall = 0.268, Specificity= 0.794, Precision = 0.271
LZ:		 Auc= 0.571, Recall = 0.359, Specificity= 0.783, Precision = 0.364
MH:		 Auc= 0.599, Recall = 0.308, Specificity= 0.890, Precision = 0.371
MK:		 Auc= 0.571, Recall = 0.287, Specificity= 0.854, Precision = 0.282
MR:		 Auc= 0.559, Recall = 0.183, Specificity= 0.935, Precision = 0.265
NK:		 Auc= 0.605, Recall = 0.277, Specificity= 0.934, Precision = 0.397
PG:		 Auc= 0.661, Recall = 0.449, Specificity= 0.873, Precision = 0.467
ST:		 Auc= 0.549, Recall = 0.160, Specificity= 0.937, Precision = 0.267

Performance scores when doing LeaveOneGroupOut with SVM

 Performance: Auc = 0.592 (+-0.042, max: 0.656), Recall = 0.345 (+-0.083, max: 0.473), Specificity= 0.840 (+-0.071, max: 0.911), Precision = 0.341 (+-0.083, max: 0.468)
	 Confusion matrix: 
		[[4332  705]
		 [ 694  390]]
	Correctly classified data: 77.14% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.644, Recall = 0.444, Specificity= 0.845, Precision = 0.444
FM:		 Auc= 0.540, Recall = 0.217, Specificity= 0.864, Precision = 0.212
TW:		 Auc= 0.557, Recall = 0.473, Specificity= 0.640, Precision = 0.468
ZZ:		 Auc= 0.631, Recall = 0.379, Specificity= 0.883, Precision = 0.363
IS:		 Auc= 0.529, Recall = 0.268, Specificity= 0.789, Precision = 0.268
LZ:		 Auc= 0.569, Recall = 0.359, Specificity= 0.779, Precision = 0.359
MH:		 Auc= 0.629, Recall = 0.393, Specificity= 0.866, Precision = 0.382
MK:		 Auc= 0.572, Recall = 0.287, Specificity= 0.856, Precision = 0.284
MR:		 Auc= 0.611, Recall = 0.310, Specificity= 0.911, Precision = 0.310
NK:		 Auc= 0.617, Recall = 0.337, Specificity= 0.896, Precision = 0.337
PG:		 Auc= 0.656, Recall = 0.449, Specificity= 0.863, Precision = 0.449
ST:		 Auc= 0.554, Recall = 0.220, Specificity= 0.889, Precision = 0.220

Performance scores when doing LeaveOneGroupOut with Linear SVM

 Performance: Auc = 0.592 (+-0.042, max: 0.656), Recall = 0.345 (+-0.083, max: 0.473), Specificity= 0.840 (+-0.071, max: 0.911), Precision = 0.341 (+-0.083, max: 0.468)
	 Confusion matrix: 
		[[4332  705]
		 [ 694  390]]
	Correctly classified data: 77.14% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.644, Recall = 0.444, Specificity= 0.845, Precision = 0.444
FM:		 Auc= 0.540, Recall = 0.217, Specificity= 0.864, Precision = 0.212
TW:		 Auc= 0.557, Recall = 0.473, Specificity= 0.640, Precision = 0.468
ZZ:		 Auc= 0.631, Recall = 0.379, Specificity= 0.883, Precision = 0.363
IS:		 Auc= 0.529, Recall = 0.268, Specificity= 0.789, Precision = 0.268
LZ:		 Auc= 0.569, Recall = 0.359, Specificity= 0.779, Precision = 0.359
MH:		 Auc= 0.629, Recall = 0.393, Specificity= 0.866, Precision = 0.382
MK:		 Auc= 0.572, Recall = 0.287, Specificity= 0.856, Precision = 0.284
MR:		 Auc= 0.611, Recall = 0.310, Specificity= 0.911, Precision = 0.310
NK:		 Auc= 0.617, Recall = 0.337, Specificity= 0.896, Precision = 0.337
PG:		 Auc= 0.656, Recall = 0.449, Specificity= 0.863, Precision = 0.449
ST:		 Auc= 0.554, Recall = 0.220, Specificity= 0.889, Precision = 0.220

Performance scores when doing LeaveOneGroupOut with Nearest Neighbor

 Performance: Auc = 0.517 (+-0.017, max: 0.549), Recall = 0.091 (+-0.029, max: 0.145), Specificity= 0.942 (+-0.021, max: 0.977), Precision = 0.278 (+-0.109, max: 0.526)
	 Confusion matrix: 
		[[4753  284]
		 [ 983  101]]
	Correctly classified data: 79.3% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.522, Recall = 0.105, Specificity= 0.939, Precision = 0.326
FM:		 Auc= 0.505, Recall = 0.084, Specificity= 0.925, Precision = 0.159
TW:		 Auc= 0.521, Recall = 0.108, Specificity= 0.935, Precision = 0.526
ZZ:		 Auc= 0.527, Recall = 0.126, Specificity= 0.928, Precision = 0.234
IS:		 Auc= 0.484, Recall = 0.056, Specificity= 0.911, Precision = 0.154
LZ:		 Auc= 0.527, Recall = 0.115, Specificity= 0.938, Precision = 0.391
MH:		 Auc= 0.512, Recall = 0.065, Specificity= 0.959, Precision = 0.250
MK:		 Auc= 0.490, Recall = 0.069, Specificity= 0.911, Precision = 0.135
MR:		 Auc= 0.530, Recall = 0.085, Specificity= 0.976, Precision = 0.316
NK:		 Auc= 0.549, Recall = 0.145, Specificity= 0.953, Precision = 0.324
PG:		 Auc= 0.523, Recall = 0.094, Specificity= 0.951, Precision = 0.324
ST:		 Auc= 0.509, Recall = 0.040, Specificity= 0.977, Precision = 0.200

Performance scores when doing LeaveOneGroupOut with QDA

 Performance: Auc = 0.546 (+-0.040, max: 0.619), Recall = 0.236 (+-0.123, max: 0.495), Specificity= 0.856 (+-0.136, max: 0.966), Precision = 0.309 (+-0.102, max: 0.486)
	 Confusion matrix: 
		[[4493  544]
		 [ 810  274]]
	Correctly classified data: 77.88% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.593, Recall = 0.308, Specificity= 0.878, Precision = 0.414
FM:		 Auc= 0.519, Recall = 0.133, Specificity= 0.905, Precision = 0.190
TW:		 Auc= 0.470, Recall = 0.495, Specificity= 0.446, Precision = 0.374
ZZ:		 Auc= 0.541, Recall = 0.172, Specificity= 0.909, Precision = 0.250
IS:		 Auc= 0.539, Recall = 0.296, Specificity= 0.781, Precision = 0.280
LZ:		 Auc= 0.554, Recall = 0.321, Specificity= 0.788, Precision = 0.342
MH:		 Auc= 0.574, Recall = 0.234, Specificity= 0.914, Precision = 0.362
MK:		 Auc= 0.545, Recall = 0.188, Specificity= 0.901, Precision = 0.275
MR:		 Auc= 0.510, Recall = 0.056, Specificity= 0.964, Precision = 0.167
NK:		 Auc= 0.585, Recall = 0.205, Specificity= 0.966, Precision = 0.486
PG:		 Auc= 0.619, Recall = 0.370, Specificity= 0.869, Precision = 0.412
ST:		 Auc= 0.507, Recall = 0.060, Specificity= 0.954, Precision = 0.158

Performance scores when doing LeaveOneGroupOut with Naive Bayes

 Performance: Auc = 0.576 (+-0.043, max: 0.661), Recall = 0.266 (+-0.115, max: 0.449), Specificity= 0.886 (+-0.059, max: 1.000), Precision = 0.306 (+-0.118, max: 0.467)
	 Confusion matrix: 
		[[4468  569]
		 [ 777  307]]
	Correctly classified data: 78.01% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.637, Recall = 0.421, Specificity= 0.853, Precision = 0.444
FM:		 Auc= 0.545, Recall = 0.217, Specificity= 0.872, Precision = 0.222
TW:		 Auc= 0.500, Recall = 0.000, Specificity= 1.000, Precision = 0.000
ZZ:		 Auc= 0.584, Recall = 0.264, Specificity= 0.903, Precision = 0.324
IS:		 Auc= 0.531, Recall = 0.268, Specificity= 0.794, Precision = 0.271
LZ:		 Auc= 0.571, Recall = 0.359, Specificity= 0.783, Precision = 0.364
MH:		 Auc= 0.599, Recall = 0.308, Specificity= 0.890, Precision = 0.371
MK:		 Auc= 0.571, Recall = 0.287, Specificity= 0.854, Precision = 0.282
MR:		 Auc= 0.559, Recall = 0.183, Specificity= 0.935, Precision = 0.265
NK:		 Auc= 0.605, Recall = 0.277, Specificity= 0.934, Precision = 0.397
PG:		 Auc= 0.661, Recall = 0.449, Specificity= 0.873, Precision = 0.467
ST:		 Auc= 0.549, Recall = 0.160, Specificity= 0.937, Precision = 0.267

Performance scores when doing LeaveOneGroupOut with SVM

 Performance: Auc = 0.592 (+-0.042, max: 0.656), Recall = 0.345 (+-0.083, max: 0.473), Specificity= 0.840 (+-0.071, max: 0.911), Precision = 0.341 (+-0.083, max: 0.468)
	 Confusion matrix: 
		[[4332  705]
		 [ 694  390]]
	Correctly classified data: 77.14% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.644, Recall = 0.444, Specificity= 0.845, Precision = 0.444
FM:		 Auc= 0.540, Recall = 0.217, Specificity= 0.864, Precision = 0.212
TW:		 Auc= 0.557, Recall = 0.473, Specificity= 0.640, Precision = 0.468
ZZ:		 Auc= 0.631, Recall = 0.379, Specificity= 0.883, Precision = 0.363
IS:		 Auc= 0.529, Recall = 0.268, Specificity= 0.789, Precision = 0.268
LZ:		 Auc= 0.569, Recall = 0.359, Specificity= 0.779, Precision = 0.359
MH:		 Auc= 0.629, Recall = 0.393, Specificity= 0.866, Precision = 0.382
MK:		 Auc= 0.572, Recall = 0.287, Specificity= 0.856, Precision = 0.284
MR:		 Auc= 0.611, Recall = 0.310, Specificity= 0.911, Precision = 0.310
NK:		 Auc= 0.617, Recall = 0.337, Specificity= 0.896, Precision = 0.337
PG:		 Auc= 0.656, Recall = 0.449, Specificity= 0.863, Precision = 0.449
ST:		 Auc= 0.554, Recall = 0.220, Specificity= 0.889, Precision = 0.220

Performance scores when doing LeaveOneGroupOut with Linear SVM

 Performance: Auc = 0.592 (+-0.042, max: 0.656), Recall = 0.345 (+-0.083, max: 0.473), Specificity= 0.840 (+-0.071, max: 0.911), Precision = 0.341 (+-0.083, max: 0.468)
	 Confusion matrix: 
		[[4332  705]
		 [ 694  390]]
	Correctly classified data: 77.14% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.644, Recall = 0.444, Specificity= 0.845, Precision = 0.444
FM:		 Auc= 0.540, Recall = 0.217, Specificity= 0.864, Precision = 0.212
TW:		 Auc= 0.557, Recall = 0.473, Specificity= 0.640, Precision = 0.468
ZZ:		 Auc= 0.631, Recall = 0.379, Specificity= 0.883, Precision = 0.363
IS:		 Auc= 0.529, Recall = 0.268, Specificity= 0.789, Precision = 0.268
LZ:		 Auc= 0.569, Recall = 0.359, Specificity= 0.779, Precision = 0.359
MH:		 Auc= 0.629, Recall = 0.393, Specificity= 0.866, Precision = 0.382
MK:		 Auc= 0.572, Recall = 0.287, Specificity= 0.856, Precision = 0.284
MR:		 Auc= 0.611, Recall = 0.310, Specificity= 0.911, Precision = 0.310
NK:		 Auc= 0.617, Recall = 0.337, Specificity= 0.896, Precision = 0.337
PG:		 Auc= 0.656, Recall = 0.449, Specificity= 0.863, Precision = 0.449
ST:		 Auc= 0.554, Recall = 0.220, Specificity= 0.889, Precision = 0.220

Performance scores when doing LeaveOneGroupOut with Nearest Neighbor

 Performance: Auc = 0.517 (+-0.017, max: 0.549), Recall = 0.091 (+-0.029, max: 0.145), Specificity= 0.942 (+-0.021, max: 0.977), Precision = 0.278 (+-0.109, max: 0.526)
	 Confusion matrix: 
		[[4753  284]
		 [ 983  101]]
	Correctly classified data: 79.3% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.522, Recall = 0.105, Specificity= 0.939, Precision = 0.326
FM:		 Auc= 0.505, Recall = 0.084, Specificity= 0.925, Precision = 0.159
TW:		 Auc= 0.521, Recall = 0.108, Specificity= 0.935, Precision = 0.526
ZZ:		 Auc= 0.527, Recall = 0.126, Specificity= 0.928, Precision = 0.234
IS:		 Auc= 0.484, Recall = 0.056, Specificity= 0.911, Precision = 0.154
LZ:		 Auc= 0.527, Recall = 0.115, Specificity= 0.938, Precision = 0.391
MH:		 Auc= 0.512, Recall = 0.065, Specificity= 0.959, Precision = 0.250
MK:		 Auc= 0.490, Recall = 0.069, Specificity= 0.911, Precision = 0.135
MR:		 Auc= 0.530, Recall = 0.085, Specificity= 0.976, Precision = 0.316
NK:		 Auc= 0.549, Recall = 0.145, Specificity= 0.953, Precision = 0.324
PG:		 Auc= 0.523, Recall = 0.094, Specificity= 0.951, Precision = 0.324
ST:		 Auc= 0.509, Recall = 0.040, Specificity= 0.977, Precision = 0.200

Performance scores when doing LeaveOneGroupOut with QDA

 Performance: Auc = 0.546 (+-0.040, max: 0.619), Recall = 0.236 (+-0.123, max: 0.495), Specificity= 0.856 (+-0.136, max: 0.966), Precision = 0.309 (+-0.102, max: 0.486)
	 Confusion matrix: 
		[[4493  544]
		 [ 810  274]]
	Correctly classified data: 77.88% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.593, Recall = 0.308, Specificity= 0.878, Precision = 0.414
FM:		 Auc= 0.519, Recall = 0.133, Specificity= 0.905, Precision = 0.190
TW:		 Auc= 0.470, Recall = 0.495, Specificity= 0.446, Precision = 0.374
ZZ:		 Auc= 0.541, Recall = 0.172, Specificity= 0.909, Precision = 0.250
IS:		 Auc= 0.539, Recall = 0.296, Specificity= 0.781, Precision = 0.280
LZ:		 Auc= 0.554, Recall = 0.321, Specificity= 0.788, Precision = 0.342
MH:		 Auc= 0.574, Recall = 0.234, Specificity= 0.914, Precision = 0.362
MK:		 Auc= 0.545, Recall = 0.188, Specificity= 0.901, Precision = 0.275
MR:		 Auc= 0.510, Recall = 0.056, Specificity= 0.964, Precision = 0.167
NK:		 Auc= 0.585, Recall = 0.205, Specificity= 0.966, Precision = 0.486
PG:		 Auc= 0.619, Recall = 0.370, Specificity= 0.869, Precision = 0.412
ST:		 Auc= 0.507, Recall = 0.060, Specificity= 0.954, Precision = 0.158

Performance scores when doing LeaveOneGroupOut with Naive Bayes

 Performance: Auc = 0.576 (+-0.043, max: 0.661), Recall = 0.266 (+-0.115, max: 0.449), Specificity= 0.886 (+-0.059, max: 1.000), Precision = 0.306 (+-0.118, max: 0.467)
	 Confusion matrix: 
		[[4468  569]
		 [ 777  307]]
	Correctly classified data: 78.01% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.637, Recall = 0.421, Specificity= 0.853, Precision = 0.444
FM:		 Auc= 0.545, Recall = 0.217, Specificity= 0.872, Precision = 0.222
TW:		 Auc= 0.500, Recall = 0.000, Specificity= 1.000, Precision = 0.000
ZZ:		 Auc= 0.584, Recall = 0.264, Specificity= 0.903, Precision = 0.324
IS:		 Auc= 0.531, Recall = 0.268, Specificity= 0.794, Precision = 0.271
LZ:		 Auc= 0.571, Recall = 0.359, Specificity= 0.783, Precision = 0.364
MH:		 Auc= 0.599, Recall = 0.308, Specificity= 0.890, Precision = 0.371
MK:		 Auc= 0.571, Recall = 0.287, Specificity= 0.854, Precision = 0.282
MR:		 Auc= 0.559, Recall = 0.183, Specificity= 0.935, Precision = 0.265
NK:		 Auc= 0.605, Recall = 0.277, Specificity= 0.934, Precision = 0.397
PG:		 Auc= 0.661, Recall = 0.449, Specificity= 0.873, Precision = 0.467
ST:		 Auc= 0.549, Recall = 0.160, Specificity= 0.937, Precision = 0.267

Performance scores when doing LeaveOneGroupOut with SVM

 Performance: Auc = 0.592 (+-0.042, max: 0.656), Recall = 0.345 (+-0.083, max: 0.473), Specificity= 0.840 (+-0.071, max: 0.911), Precision = 0.341 (+-0.083, max: 0.468)
	 Confusion matrix: 
		[[4332  705]
		 [ 694  390]]
	Correctly classified data: 77.14% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.644, Recall = 0.444, Specificity= 0.845, Precision = 0.444
FM:		 Auc= 0.540, Recall = 0.217, Specificity= 0.864, Precision = 0.212
TW:		 Auc= 0.557, Recall = 0.473, Specificity= 0.640, Precision = 0.468
ZZ:		 Auc= 0.631, Recall = 0.379, Specificity= 0.883, Precision = 0.363
IS:		 Auc= 0.529, Recall = 0.268, Specificity= 0.789, Precision = 0.268
LZ:		 Auc= 0.569, Recall = 0.359, Specificity= 0.779, Precision = 0.359
MH:		 Auc= 0.629, Recall = 0.393, Specificity= 0.866, Precision = 0.382
MK:		 Auc= 0.572, Recall = 0.287, Specificity= 0.856, Precision = 0.284
MR:		 Auc= 0.611, Recall = 0.310, Specificity= 0.911, Precision = 0.310
NK:		 Auc= 0.617, Recall = 0.337, Specificity= 0.896, Precision = 0.337
PG:		 Auc= 0.656, Recall = 0.449, Specificity= 0.863, Precision = 0.449
ST:		 Auc= 0.554, Recall = 0.220, Specificity= 0.889, Precision = 0.220

Performance scores when doing LeaveOneGroupOut with Linear SVM

 Performance: Auc = 0.592 (+-0.042, max: 0.656), Recall = 0.345 (+-0.083, max: 0.473), Specificity= 0.840 (+-0.071, max: 0.911), Precision = 0.341 (+-0.083, max: 0.468)
	 Confusion matrix: 
		[[4332  705]
		 [ 694  390]]
	Correctly classified data: 77.14% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.644, Recall = 0.444, Specificity= 0.845, Precision = 0.444
FM:		 Auc= 0.540, Recall = 0.217, Specificity= 0.864, Precision = 0.212
TW:		 Auc= 0.557, Recall = 0.473, Specificity= 0.640, Precision = 0.468
ZZ:		 Auc= 0.631, Recall = 0.379, Specificity= 0.883, Precision = 0.363
IS:		 Auc= 0.529, Recall = 0.268, Specificity= 0.789, Precision = 0.268
LZ:		 Auc= 0.569, Recall = 0.359, Specificity= 0.779, Precision = 0.359
MH:		 Auc= 0.629, Recall = 0.393, Specificity= 0.866, Precision = 0.382
MK:		 Auc= 0.572, Recall = 0.287, Specificity= 0.856, Precision = 0.284
MR:		 Auc= 0.611, Recall = 0.310, Specificity= 0.911, Precision = 0.310
NK:		 Auc= 0.617, Recall = 0.337, Specificity= 0.896, Precision = 0.337
PG:		 Auc= 0.656, Recall = 0.449, Specificity= 0.863, Precision = 0.449
ST:		 Auc= 0.554, Recall = 0.220, Specificity= 0.889, Precision = 0.220

Performance scores when doing LeaveOneGroupOut with Nearest Neighbor

 Performance: Auc = 0.517 (+-0.017, max: 0.549), Recall = 0.091 (+-0.029, max: 0.145), Specificity= 0.942 (+-0.021, max: 0.977), Precision = 0.278 (+-0.109, max: 0.526)
	 Confusion matrix: 
		[[4753  284]
		 [ 983  101]]
	Correctly classified data: 79.3% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.522, Recall = 0.105, Specificity= 0.939, Precision = 0.326
FM:		 Auc= 0.505, Recall = 0.084, Specificity= 0.925, Precision = 0.159
TW:		 Auc= 0.521, Recall = 0.108, Specificity= 0.935, Precision = 0.526
ZZ:		 Auc= 0.527, Recall = 0.126, Specificity= 0.928, Precision = 0.234
IS:		 Auc= 0.484, Recall = 0.056, Specificity= 0.911, Precision = 0.154
LZ:		 Auc= 0.527, Recall = 0.115, Specificity= 0.938, Precision = 0.391
MH:		 Auc= 0.512, Recall = 0.065, Specificity= 0.959, Precision = 0.250
MK:		 Auc= 0.490, Recall = 0.069, Specificity= 0.911, Precision = 0.135
MR:		 Auc= 0.530, Recall = 0.085, Specificity= 0.976, Precision = 0.316
NK:		 Auc= 0.549, Recall = 0.145, Specificity= 0.953, Precision = 0.324
PG:		 Auc= 0.523, Recall = 0.094, Specificity= 0.951, Precision = 0.324
ST:		 Auc= 0.509, Recall = 0.040, Specificity= 0.977, Precision = 0.200

Performance scores when doing LeaveOneGroupOut with QDA

 Performance: Auc = 0.546 (+-0.040, max: 0.619), Recall = 0.236 (+-0.123, max: 0.495), Specificity= 0.856 (+-0.136, max: 0.966), Precision = 0.309 (+-0.102, max: 0.486)
	 Confusion matrix: 
		[[4493  544]
		 [ 810  274]]
	Correctly classified data: 77.88% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.593, Recall = 0.308, Specificity= 0.878, Precision = 0.414
FM:		 Auc= 0.519, Recall = 0.133, Specificity= 0.905, Precision = 0.190
TW:		 Auc= 0.470, Recall = 0.495, Specificity= 0.446, Precision = 0.374
ZZ:		 Auc= 0.541, Recall = 0.172, Specificity= 0.909, Precision = 0.250
IS:		 Auc= 0.539, Recall = 0.296, Specificity= 0.781, Precision = 0.280
LZ:		 Auc= 0.554, Recall = 0.321, Specificity= 0.788, Precision = 0.342
MH:		 Auc= 0.574, Recall = 0.234, Specificity= 0.914, Precision = 0.362
MK:		 Auc= 0.545, Recall = 0.188, Specificity= 0.901, Precision = 0.275
MR:		 Auc= 0.510, Recall = 0.056, Specificity= 0.964, Precision = 0.167
NK:		 Auc= 0.585, Recall = 0.205, Specificity= 0.966, Precision = 0.486
PG:		 Auc= 0.619, Recall = 0.370, Specificity= 0.869, Precision = 0.412
ST:		 Auc= 0.507, Recall = 0.060, Specificity= 0.954, Precision = 0.158

Performance scores when doing LeaveOneGroupOut with Naive Bayes

 Performance: Auc = 0.576 (+-0.043, max: 0.661), Recall = 0.266 (+-0.115, max: 0.449), Specificity= 0.886 (+-0.059, max: 1.000), Precision = 0.306 (+-0.118, max: 0.467)
	 Confusion matrix: 
		[[4468  569]
		 [ 777  307]]
	Correctly classified data: 78.01% (vs. null accuracy: 82.29%)

roc_auc score for each user that was left out in training set and predicted on in test_set:
EK:		 Auc= 0.637, Recall = 0.421, Specificity= 0.853, Precision = 0.444
FM:		 Auc= 0.545, Recall = 0.217, Specificity= 0.872, Precision = 0.222
TW:		 Auc= 0.500, Recall = 0.000, Specificity= 1.000, Precision = 0.000
ZZ:		 Auc= 0.584, Recall = 0.264, Specificity= 0.903, Precision = 0.324
IS:		 Auc= 0.531, Recall = 0.268, Specificity= 0.794, Precision = 0.271
LZ:		 Auc= 0.571, Recall = 0.359, Specificity= 0.783, Precision = 0.364
MH:		 Auc= 0.599, Recall = 0.308, Specificity= 0.890, Precision = 0.371
MK:		 Auc= 0.571, Recall = 0.287, Specificity= 0.854, Precision = 0.282
MR:		 Auc= 0.559, Recall = 0.183, Specificity= 0.935, Precision = 0.265
NK:		 Auc= 0.605, Recall = 0.277, Specificity= 0.934, Precision = 0.397
PG:		 Auc= 0.661, Recall = 0.449, Specificity= 0.873, Precision = 0.467
ST:		 Auc= 0.549, Recall = 0.160, Specificity= 0.937, Precision = 0.267